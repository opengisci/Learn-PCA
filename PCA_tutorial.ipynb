{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbef84f-ef31-4e80-9bc1-25aec29dd394",
   "metadata": {},
   "source": [
    "# Steps in Principal Component Analysis\n",
    "Source: https://online.stat.psu.edu/stat505/lesson/11 lessons 11 and 12.\n",
    "\n",
    "You can check our results against theirs starting at 11.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484ed60-ecd3-465c-af4e-2386db3f1fd9",
   "metadata": {},
   "source": [
    "## 0: What does Principal Component Analysis (PCA) do?\n",
    "The goal of PCA is to reduce the dimensionality of input data.\n",
    "Given a large number of input variables, PCA allows us to explain most of the variability of the data with far fewer variables.\n",
    "Principal components are chosen in a way that explains as much of the variation within the data as possible.\n",
    "The first component explains the most variation, followed by the second, etc.\n",
    "Visually, principal components are lines through the data that are as close to the cloud of data as possible, while remaining perpendicular to each other.\n",
    "\n",
    "This YouTube video does a good job of explaining generally what PCA does without explaining any of the math: https://youtu.be/pmG4K79DUoI.\n",
    "The same guy has a follow up video to explain the math, if anyone is interested: https://youtu.be/dhK8nbtii6I.\n",
    "\n",
    "In the rest of this script, we will see step-by-step the operations needed to conduct PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a331db-80bd-4270-be85-783d859becc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data\n",
    "places = pd.read_csv(\"places.csv\")\n",
    "\n",
    "# Drop id column\n",
    "places = places.drop(axis = 1, columns = {\"id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb9e93-8e80-4560-a8ed-2915e010a598",
   "metadata": {},
   "source": [
    "## 1: Standardization\n",
    "Calculate the [Z-score](https://www.investopedia.com/terms/z/zscore.asp) for every variable.\n",
    "This prevents any one variable from having more influence than any other variable just because its values and variance tend to be larger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49141257-345a-43e6-9454-a0f4ccd4afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "for col in places.columns:\n",
    "    places[col] = np.log10(places[col]) # the tutorial took a log transform to deal with skew\n",
    "    places[col] = ( places[col] - np.mean(places[col]) ) / np.std(places[col], ddof=1) # ddof = 1 is to compute sample standard deviation instead of population standard deviation\n",
    "    # In some instances, it is preferred to center rather than scale your data. To center, comment out the line above and uncomment the line below \n",
    "    # places[col] = ( places[col] - np.mean(places[col]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786f559-101b-4294-b7b7-01c259b8fcf4",
   "metadata": {},
   "source": [
    "## 2: Covariance matrix\n",
    "Calculate the [covariance](https://corporatefinanceinstitute.com/resources/data-science/covariance/) between each variable in the standardized dataset and construct a covariance matrix. \n",
    "If we call the standardized matrix $X$, then we calculate the covariance matrix as $X^T X \\frac{1}{n-1}$.\n",
    "Covariance measures the level of variability between two variables.\n",
    "Note that the covariance matrix of the standardized data is equivalent to the Pearson correlation matrix of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8673528-35ce-4e59-a2ce-a266d1d3f81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climate</th>\n",
       "      <th>housing</th>\n",
       "      <th>health</th>\n",
       "      <th>crime</th>\n",
       "      <th>trans</th>\n",
       "      <th>educate</th>\n",
       "      <th>arts</th>\n",
       "      <th>recreate</th>\n",
       "      <th>econ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272964</td>\n",
       "      <td>0.150561</td>\n",
       "      <td>0.227751</td>\n",
       "      <td>0.021559</td>\n",
       "      <td>0.077458</td>\n",
       "      <td>0.172683</td>\n",
       "      <td>0.120610</td>\n",
       "      <td>-0.100727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.272964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431935</td>\n",
       "      <td>0.139234</td>\n",
       "      <td>0.317732</td>\n",
       "      <td>0.202088</td>\n",
       "      <td>0.508501</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.297058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.150561</td>\n",
       "      <td>0.431935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183625</td>\n",
       "      <td>0.418850</td>\n",
       "      <td>0.464764</td>\n",
       "      <td>0.678129</td>\n",
       "      <td>0.254036</td>\n",
       "      <td>0.054047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.227751</td>\n",
       "      <td>0.139234</td>\n",
       "      <td>0.183625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273852</td>\n",
       "      <td>0.055508</td>\n",
       "      <td>0.346462</td>\n",
       "      <td>0.292124</td>\n",
       "      <td>0.276182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.021559</td>\n",
       "      <td>0.317732</td>\n",
       "      <td>0.418850</td>\n",
       "      <td>0.273852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311237</td>\n",
       "      <td>0.547634</td>\n",
       "      <td>0.390684</td>\n",
       "      <td>0.062680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.077458</td>\n",
       "      <td>0.202088</td>\n",
       "      <td>0.464764</td>\n",
       "      <td>0.055508</td>\n",
       "      <td>0.311237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347899</td>\n",
       "      <td>0.093001</td>\n",
       "      <td>0.128858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.172683</td>\n",
       "      <td>0.508501</td>\n",
       "      <td>0.678129</td>\n",
       "      <td>0.346462</td>\n",
       "      <td>0.547634</td>\n",
       "      <td>0.347899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496519</td>\n",
       "      <td>0.134761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.120610</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.254036</td>\n",
       "      <td>0.292124</td>\n",
       "      <td>0.390684</td>\n",
       "      <td>0.093001</td>\n",
       "      <td>0.496519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>econ</th>\n",
       "      <td>-0.100727</td>\n",
       "      <td>0.297058</td>\n",
       "      <td>0.054047</td>\n",
       "      <td>0.276182</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>0.128858</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.175914</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           climate   housing    health     crime     trans   educate  \\\n",
       "climate   1.000000  0.272964  0.150561  0.227751  0.021559  0.077458   \n",
       "housing   0.272964  1.000000  0.431935  0.139234  0.317732  0.202088   \n",
       "health    0.150561  0.431935  1.000000  0.183625  0.418850  0.464764   \n",
       "crime     0.227751  0.139234  0.183625  1.000000  0.273852  0.055508   \n",
       "trans     0.021559  0.317732  0.418850  0.273852  1.000000  0.311237   \n",
       "educate   0.077458  0.202088  0.464764  0.055508  0.311237  1.000000   \n",
       "arts      0.172683  0.508501  0.678129  0.346462  0.547634  0.347899   \n",
       "recreate  0.120610  0.460696  0.254036  0.292124  0.390684  0.093001   \n",
       "econ     -0.100727  0.297058  0.054047  0.276182  0.062680  0.128858   \n",
       "\n",
       "              arts  recreate      econ  \n",
       "climate   0.172683  0.120610 -0.100727  \n",
       "housing   0.508501  0.460696  0.297058  \n",
       "health    0.678129  0.254036  0.054047  \n",
       "crime     0.346462  0.292124  0.276182  \n",
       "trans     0.547634  0.390684  0.062680  \n",
       "educate   0.347899  0.093001  0.128858  \n",
       "arts      1.000000  0.496519  0.134761  \n",
       "recreate  0.496519  1.000000  0.175914  \n",
       "econ      0.134761  0.175914  1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate covariance matrix (covariance matrix of standardized variables is the same as a correlation matrix of the original variables)\n",
    "cov_matrix = (places.T).dot(places)*(1/ (len(places)-1))\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9db548-e33c-4ec7-903e-bb33e734882a",
   "metadata": {},
   "source": [
    "## 3: Eigenvalues and eigenvectors\n",
    "Compute [eigenvalues and eigenvectors](https://math.libretexts.org/Bookshelves/Linear_Algebra/A_First_Course_in_Linear_Algebra_(Kuttler)/07%3A_Spectral_Theory/7.01%3A_Eigenvalues_and_Eigenvectors_of_a_Matrix) of the covariance matrix.\n",
    "An eigenvector $x$ of a matrix $A$ is one such that $Ax = \\lambda x$ for some number $\\lambda$ (left-multiplying the vector by the matrix is the same as multiplying the vector by some constant $\\lambda$).\n",
    "The eigenvectors are our principal components.\n",
    "Each component has an entry for every variable; these entries are called weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80eb083-e428-45ff-8d7a-a8d63b7a5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array\n",
    "cov_matrix = cov_matrix.values\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d4144-1547-474a-8942-ff2140c8db4e",
   "metadata": {},
   "source": [
    "## 4: Rank components\n",
    "Rank the eigenvectors from most to least important by their eigenvalues.\n",
    "The bigger the eigenvalue, the more variance explained by its corresponding component, the more important the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdecb5da-7e20-456d-8be4-536e7b8b1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine eigenvalues and eigenvectors into one list\n",
    "eigenzip = list(zip(eigenvalues, eigenvectors.T))\n",
    "\n",
    "# Sort by eigenvalue \n",
    "sorted_eigenzip = sorted(eigenzip, key = lambda x:x[0], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39f233-2883-49e4-bce3-e0a94732bc45",
   "metadata": {},
   "source": [
    "## 5: Calculate percent variance explained \n",
    "This formula calculates the proportion of variance explained by the ith of all n eigenvectors:\n",
    "\n",
    "$$ \\frac{\\lambda_i}{\\lambda_1 + \\lambda_2 + ... + \\lambda_n} $$\n",
    "\n",
    "And this formula calculates the proportion of variance explained by the first r of all n eigenvectors.\n",
    "\n",
    "$$ \\frac{\\lambda_1 + \\lambda_2 + ... + \\lambda_r}{\\lambda_1 + \\lambda_2 + ... + \\lambda_n} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453e5ed4-a00a-4fd6-9c97-fbf0fa14b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = eigenvalues.sum()\n",
    "\n",
    "eigenval_summary = pd.DataFrame( {\"Component\": np.NaN,\n",
    "                                  \"Eigenvalue\": np.NaN,\n",
    "                                  \"Proportion\": np.NaN,\n",
    "                                  \"Cumulative\": np.NaN},\n",
    "                               index = [i for i in range(len(eigenvalues))])\n",
    "\n",
    "eigenvecs_sorted = pd.DataFrame(eigenvectors)\n",
    "\n",
    "cumulative = 0\n",
    "\n",
    "for i in range(len(sorted_eigenzip)):\n",
    "    eigenval_summary[\"Component\"][i] = i+1\n",
    "    \n",
    "    eigenval_summary[\"Eigenvalue\"][i] = sorted_eigenzip[i][0]\n",
    "    \n",
    "    eigenval_summary[\"Proportion\"][i] = eigenval_summary[\"Eigenvalue\"][i]/tot\n",
    "    \n",
    "    cumulative += eigenval_summary[\"Proportion\"][i]\n",
    "    eigenval_summary[\"Cumulative\"][i] = cumulative\n",
    "    \n",
    "    eigenvecs_sorted[i] = sorted_eigenzip[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05ba54a-ad8f-45a3-b900-3d7027c02738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component</th>\n",
       "      <th>Eigenvalue</th>\n",
       "      <th>Proportion</th>\n",
       "      <th>Cumulative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.297793</td>\n",
       "      <td>0.366421</td>\n",
       "      <td>0.366421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.213562</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>0.501262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.105530</td>\n",
       "      <td>0.122837</td>\n",
       "      <td>0.624098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.907280</td>\n",
       "      <td>0.100809</td>\n",
       "      <td>0.724907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.860629</td>\n",
       "      <td>0.095625</td>\n",
       "      <td>0.820533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.562186</td>\n",
       "      <td>0.062465</td>\n",
       "      <td>0.882998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.483821</td>\n",
       "      <td>0.053758</td>\n",
       "      <td>0.936756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.318072</td>\n",
       "      <td>0.035341</td>\n",
       "      <td>0.972097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.251128</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Component  Eigenvalue  Proportion  Cumulative\n",
       "0        1.0    3.297793    0.366421    0.366421\n",
       "1        2.0    1.213562    0.134840    0.501262\n",
       "2        3.0    1.105530    0.122837    0.624098\n",
       "3        4.0    0.907280    0.100809    0.724907\n",
       "4        5.0    0.860629    0.095625    0.820533\n",
       "5        6.0    0.562186    0.062465    0.882998\n",
       "6        7.0    0.483821    0.053758    0.936756\n",
       "7        8.0    0.318072    0.035341    0.972097\n",
       "8        9.0    0.251128    0.027903    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total eigenvalue sum: 9.0\n"
     ]
    }
   ],
   "source": [
    "display(eigenval_summary)\n",
    "print(\"Total eigenvalue sum:\", tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453c45b-f8d6-4a63-9d69-19c9e1dfefc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6: Calculate loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a613cf-5333-4e49-bd89-5a51fe7f346a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Apparently there is a difference between eigenvectors and the vectors of loadings.\n",
    "By multiplying by the square root of the eigenvalue, our results become more interpretable, as we shall see below.\n",
    "First we will inspect the original eigenvectors, then we will calculate loadings and inspect them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8eabaf-018e-4e06-8d27-3562cf8123ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.157941</td>\n",
       "      <td>0.068629</td>\n",
       "      <td>0.799710</td>\n",
       "      <td>-0.376810</td>\n",
       "      <td>0.041046</td>\n",
       "      <td>0.216695</td>\n",
       "      <td>-0.151352</td>\n",
       "      <td>0.341128</td>\n",
       "      <td>-0.030098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.384405</td>\n",
       "      <td>0.139209</td>\n",
       "      <td>0.079616</td>\n",
       "      <td>-0.196543</td>\n",
       "      <td>-0.579868</td>\n",
       "      <td>-0.082220</td>\n",
       "      <td>-0.275197</td>\n",
       "      <td>-0.606101</td>\n",
       "      <td>0.042269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.409910</td>\n",
       "      <td>-0.371812</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>-0.112522</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>-0.534876</td>\n",
       "      <td>0.134975</td>\n",
       "      <td>0.150058</td>\n",
       "      <td>-0.594128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.259102</td>\n",
       "      <td>0.474132</td>\n",
       "      <td>0.128467</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.692171</td>\n",
       "      <td>-0.139901</td>\n",
       "      <td>0.109504</td>\n",
       "      <td>-0.420125</td>\n",
       "      <td>-0.051012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.374889</td>\n",
       "      <td>-0.141486</td>\n",
       "      <td>-0.141068</td>\n",
       "      <td>0.430077</td>\n",
       "      <td>0.191416</td>\n",
       "      <td>0.323891</td>\n",
       "      <td>-0.678567</td>\n",
       "      <td>0.118833</td>\n",
       "      <td>-0.135843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.274325</td>\n",
       "      <td>-0.452355</td>\n",
       "      <td>-0.241056</td>\n",
       "      <td>-0.456943</td>\n",
       "      <td>0.224744</td>\n",
       "      <td>0.526583</td>\n",
       "      <td>0.262096</td>\n",
       "      <td>-0.211175</td>\n",
       "      <td>0.110124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.473847</td>\n",
       "      <td>-0.104410</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.146881</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>-0.321057</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.259867</td>\n",
       "      <td>0.746727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.353412</td>\n",
       "      <td>0.291942</td>\n",
       "      <td>0.041816</td>\n",
       "      <td>0.404019</td>\n",
       "      <td>-0.305654</td>\n",
       "      <td>0.394139</td>\n",
       "      <td>0.553094</td>\n",
       "      <td>0.137718</td>\n",
       "      <td>-0.226365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>0.164013</td>\n",
       "      <td>0.540453</td>\n",
       "      <td>-0.507310</td>\n",
       "      <td>-0.475780</td>\n",
       "      <td>-0.037108</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>-0.146867</td>\n",
       "      <td>0.414774</td>\n",
       "      <td>-0.047903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "climate   0.157941  0.068629  0.799710 -0.376810  0.041046  0.216695   \n",
       "housing   0.384405  0.139209  0.079616 -0.196543 -0.579868 -0.082220   \n",
       "health    0.409910 -0.371812 -0.019475 -0.112522  0.029569 -0.534876   \n",
       "crime     0.259102  0.474132  0.128467  0.042300  0.692171 -0.139901   \n",
       "trans     0.374889 -0.141486 -0.141068  0.430077  0.191416  0.323891   \n",
       "educate   0.274325 -0.452355 -0.241056 -0.456943  0.224744  0.526583   \n",
       "arts      0.473847 -0.104410  0.011026  0.146881  0.011930 -0.321057   \n",
       "recreate  0.353412  0.291942  0.041816  0.404019 -0.305654  0.394139   \n",
       "economy   0.164013  0.540453 -0.507310 -0.475780 -0.037108 -0.000974   \n",
       "\n",
       "                 6         7         8  \n",
       "climate  -0.151352  0.341128 -0.030098  \n",
       "housing  -0.275197 -0.606101  0.042269  \n",
       "health    0.134975  0.150058 -0.594128  \n",
       "crime     0.109504 -0.420125 -0.051012  \n",
       "trans    -0.678567  0.118833 -0.135843  \n",
       "educate   0.262096 -0.211175  0.110124  \n",
       "arts      0.120499  0.259867  0.746727  \n",
       "recreate  0.553094  0.137718 -0.226365  \n",
       "economy  -0.146867  0.414774 -0.047903  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse signs\n",
    "eigenvecs_sorted = (eigenvecs_sorted*-1)#.round(3) # for some reason everything had the opposite sign in ours...\n",
    "# The choice of sign for eigenvectors is arbitrary... but how does that affect our SoVI calculation? \n",
    "# https://github.com/tidymodels/recipes/issues/653\n",
    "# https://www.mathworks.com/help/stats/pca.html\n",
    "\n",
    "# Inspect components\n",
    "eigenvecs_sorted = eigenvecs_sorted.set_index(keys = pd.Index([\"climate\", \"housing\", \"health\", \"crime\", \"trans\", \"educate\", \"arts\", \"recreate\", \"economy\"]))\n",
    "eigenvecs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8bac150-f0ba-43a0-98af-10798cf1bc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7    1.0\n",
       "8    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just illustrating that the eigenvectors are of unit length\n",
    "(eigenvecs_sorted**2).sum(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c054c85-39a0-41d0-a964-bc9b37367770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.286819</td>\n",
       "      <td>0.075603</td>\n",
       "      <td>0.840848</td>\n",
       "      <td>-0.358916</td>\n",
       "      <td>0.038078</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>-0.105276</td>\n",
       "      <td>0.192389</td>\n",
       "      <td>-0.015083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.698073</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.083712</td>\n",
       "      <td>-0.187210</td>\n",
       "      <td>-0.537944</td>\n",
       "      <td>-0.061648</td>\n",
       "      <td>-0.191419</td>\n",
       "      <td>-0.341828</td>\n",
       "      <td>0.021182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.744389</td>\n",
       "      <td>-0.409595</td>\n",
       "      <td>-0.020477</td>\n",
       "      <td>-0.107179</td>\n",
       "      <td>0.027432</td>\n",
       "      <td>-0.401045</td>\n",
       "      <td>0.093885</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>-0.297733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.470524</td>\n",
       "      <td>0.522313</td>\n",
       "      <td>0.135076</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>0.642128</td>\n",
       "      <td>-0.104896</td>\n",
       "      <td>0.076168</td>\n",
       "      <td>-0.236942</td>\n",
       "      <td>-0.025563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.680792</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>-0.148325</td>\n",
       "      <td>0.409653</td>\n",
       "      <td>0.177577</td>\n",
       "      <td>0.242851</td>\n",
       "      <td>-0.471992</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>-0.068075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.498170</td>\n",
       "      <td>-0.498323</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.435244</td>\n",
       "      <td>0.208495</td>\n",
       "      <td>0.394827</td>\n",
       "      <td>0.182307</td>\n",
       "      <td>-0.119098</td>\n",
       "      <td>0.055186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.860498</td>\n",
       "      <td>-0.115020</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.139906</td>\n",
       "      <td>0.011068</td>\n",
       "      <td>-0.240726</td>\n",
       "      <td>0.083815</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>0.374205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.641790</td>\n",
       "      <td>0.321609</td>\n",
       "      <td>0.043967</td>\n",
       "      <td>0.384833</td>\n",
       "      <td>-0.283555</td>\n",
       "      <td>0.295522</td>\n",
       "      <td>0.384717</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>-0.113438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>0.297846</td>\n",
       "      <td>0.595373</td>\n",
       "      <td>-0.533407</td>\n",
       "      <td>-0.453186</td>\n",
       "      <td>-0.034425</td>\n",
       "      <td>-0.000730</td>\n",
       "      <td>-0.102157</td>\n",
       "      <td>0.233924</td>\n",
       "      <td>-0.024005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "climate   0.286819  0.075603  0.840848 -0.358916  0.038078  0.162476   \n",
       "housing   0.698073  0.153355  0.083712 -0.187210 -0.537944 -0.061648   \n",
       "health    0.744389 -0.409595 -0.020477 -0.107179  0.027432 -0.401045   \n",
       "crime     0.470524  0.522313  0.135076  0.040291  0.642128 -0.104896   \n",
       "trans     0.680792 -0.155864 -0.148325  0.409653  0.177577  0.242851   \n",
       "educate   0.498170 -0.498323 -0.253456 -0.435244  0.208495  0.394827   \n",
       "arts      0.860498 -0.115020  0.011593  0.139906  0.011068 -0.240726   \n",
       "recreate  0.641790  0.321609  0.043967  0.384833 -0.283555  0.295522   \n",
       "economy   0.297846  0.595373 -0.533407 -0.453186 -0.034425 -0.000730   \n",
       "\n",
       "                 6         7         8  \n",
       "climate  -0.105276  0.192389 -0.015083  \n",
       "housing  -0.191419 -0.341828  0.021182  \n",
       "health    0.093885  0.084629 -0.297733  \n",
       "crime     0.076168 -0.236942 -0.025563  \n",
       "trans    -0.471992  0.067019 -0.068075  \n",
       "educate   0.182307 -0.119098  0.055186  \n",
       "arts      0.083815  0.146560  0.374205  \n",
       "recreate  0.384717  0.077670 -0.113438  \n",
       "economy  -0.102157  0.233924 -0.024005  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate factor loadings\n",
    "# Note: may need a different procedure if you chose to center rather than standardize the data\n",
    "factor_loadings = eigenvecs_sorted\n",
    "for i in range( len(eigenvecs_sorted) ):\n",
    "    factor_loadings[i] = factor_loadings[i]*np.sqrt(eigenval_summary[\"Eigenvalue\"][i])\n",
    "factor_loadings#.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520379b-06c6-4a8e-bf12-87deb33ef3a5",
   "metadata": {},
   "source": [
    "Note: we can think of factor loadings as correlations between factors and input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2928f485-eb8d-4a9c-a12c-58245792a30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.297793\n",
       "1    1.213562\n",
       "2    1.105530\n",
       "3    0.907280\n",
       "4    0.860629\n",
       "5    0.562186\n",
       "6    0.483821\n",
       "7    0.318072\n",
       "8    0.251128\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of squared loadings: relationship with eigenvalue\n",
    "(factor_loadings**2).sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a13a1f-36ff-4aac-8d81-167b42c1347d",
   "metadata": {},
   "source": [
    "Column-wise, we can see that the sum of the squared loadings for a component equals the component's eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a177ec2-9d98-4357-9e62-1a5a669628d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "climate     1.0\n",
       "housing     1.0\n",
       "health      1.0\n",
       "crime       1.0\n",
       "trans       1.0\n",
       "educate     1.0\n",
       "arts        1.0\n",
       "recreate    1.0\n",
       "economy     1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Communalities\n",
    "(factor_loadings**2).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e2fe3-c00b-42f3-9e28-d40d23885604",
   "metadata": {},
   "source": [
    "Row-wise, we can see that the 9 components explain 100% of variance  for each variable, because for each variable, the sum of the squared loadings amongst all of the components is 1.\n",
    "For a given variable, the squared corresponding entry in a component tells you how much variance of that variable is explained by that component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8efd5-fb15-4c00-bf12-2d499f2a9515",
   "metadata": {},
   "source": [
    "## 7: Select components\n",
    "\n",
    "Initially, we derive the same number of components as there are variables in the model.\n",
    "Since the goal is to reduce the dimensionality of the dataset, we typically seek to select a subset of the components.\n",
    "In the Penn State tutorial, the authors select the first three components, and in order to check our results against theirs, we do the same here.\n",
    "SoVI employs the Kaiser criterion, which means retaining all components with eigenvalues of at least 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216b5a05-8392-42f6-bdc5-c04e7a4213f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3 = factor_loadings[[0,1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab313d-022c-4133-82f9-e59978cc99a0",
   "metadata": {},
   "source": [
    "## 8: Calculate communalities\n",
    "\n",
    "Communalities are calculated as\n",
    "$\\sum_{j=1}^{m} l_{ij}^2$,\n",
    "where $m$ is the number of retained components and $l_{ij}$ is the loading corresponding to variable $i$ and component $j$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "976aa862-12de-41df-8b21-adbfb0fdda59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Communality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate</td>\n",
       "      <td>0.795007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.517832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>0.722302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crime</td>\n",
       "      <td>0.512449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.509772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>educate</td>\n",
       "      <td>0.560739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arts</td>\n",
       "      <td>0.753821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recreate</td>\n",
       "      <td>0.517259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>economy</td>\n",
       "      <td>0.727704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable Communality\n",
       "0   climate    0.795007\n",
       "1   housing    0.517832\n",
       "2    health    0.722302\n",
       "3     crime    0.512449\n",
       "4     trans    0.509772\n",
       "5   educate    0.560739\n",
       "6      arts    0.753821\n",
       "7  recreate    0.517259\n",
       "8   economy    0.727704"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Communalities of first three components\n",
    "communalities = pd.DataFrame(columns = {\"Variable\", \"Communality\"}, index = [i for i in range(len(factor_loadings))])\n",
    "for i in range(len(top3)):\n",
    "    communalities[\"Variable\"][i] = top3.index[i]\n",
    "    communalities[\"Communality\"][i] = (top3.iloc[i]**2).sum()\n",
    "communalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a707252-6633-405f-b921-f19f0ad70b14",
   "metadata": {},
   "source": [
    "Communalities can be interpreted like $R^2$ values in regression models. For example, the first three factors explain 79.5% of the variation in the climate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0311663-fc22-4760-8a48-4045dd535ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.616884741577941"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total communality value\n",
    "communalities[\"Communality\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ee3115-3abb-4f62-b19b-0d1d47d6a52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6240983046197712"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of total variance explained by the 3 factors\n",
    "communalities[\"Communality\"].sum()/len(factor_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8617b2a1-99e9-4721-89bc-57cf07835c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6240983046197713"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, we get the same number by calculating the proportion of variance explained using eigenvalues\n",
    "eigenval_summary[\"Eigenvalue\"][0:3].sum()/eigenval_summary[\"Eigenvalue\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aecfc1-a5d9-4793-9e78-1cafbd066a5c",
   "metadata": {},
   "source": [
    "## 9: Calculating scores\n",
    "To calculate component scores, we first have to scale the components by dividing them by their eigenvalue.\n",
    "Calculating scores is equivalent to translating them to a new coordinate system, where the axes are the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accedf29-d368-42bb-b17d-7c8995053b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.086973</td>\n",
       "      <td>0.062299</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>-1.429213</td>\n",
       "      <td>0.119716</td>\n",
       "      <td>0.335818</td>\n",
       "      <td>-0.187262</td>\n",
       "      <td>0.212050</td>\n",
       "      <td>-0.017525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.211679</td>\n",
       "      <td>0.126368</td>\n",
       "      <td>0.075721</td>\n",
       "      <td>-0.745475</td>\n",
       "      <td>-1.691264</td>\n",
       "      <td>-0.127419</td>\n",
       "      <td>-0.340491</td>\n",
       "      <td>-0.376762</td>\n",
       "      <td>0.024612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.225723</td>\n",
       "      <td>-0.337515</td>\n",
       "      <td>-0.018523</td>\n",
       "      <td>-0.426789</td>\n",
       "      <td>0.086243</td>\n",
       "      <td>-0.828912</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.093278</td>\n",
       "      <td>-0.345949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.142679</td>\n",
       "      <td>0.430396</td>\n",
       "      <td>0.122182</td>\n",
       "      <td>0.160440</td>\n",
       "      <td>2.018811</td>\n",
       "      <td>-0.216808</td>\n",
       "      <td>0.135485</td>\n",
       "      <td>-0.261156</td>\n",
       "      <td>-0.029703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.206439</td>\n",
       "      <td>-0.128435</td>\n",
       "      <td>-0.134167</td>\n",
       "      <td>1.631252</td>\n",
       "      <td>0.558291</td>\n",
       "      <td>0.501944</td>\n",
       "      <td>-0.839566</td>\n",
       "      <td>0.073868</td>\n",
       "      <td>-0.079099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.151062</td>\n",
       "      <td>-0.410628</td>\n",
       "      <td>-0.229262</td>\n",
       "      <td>-1.733154</td>\n",
       "      <td>0.655496</td>\n",
       "      <td>0.816060</td>\n",
       "      <td>0.324282</td>\n",
       "      <td>-0.131270</td>\n",
       "      <td>0.064123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.260931</td>\n",
       "      <td>-0.094779</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.557111</td>\n",
       "      <td>0.034796</td>\n",
       "      <td>-0.497551</td>\n",
       "      <td>0.149089</td>\n",
       "      <td>0.161537</td>\n",
       "      <td>0.434804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.194612</td>\n",
       "      <td>0.265012</td>\n",
       "      <td>0.039771</td>\n",
       "      <td>1.532417</td>\n",
       "      <td>-0.891481</td>\n",
       "      <td>0.610808</td>\n",
       "      <td>0.684323</td>\n",
       "      <td>0.085608</td>\n",
       "      <td>-0.131808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>0.090317</td>\n",
       "      <td>0.490599</td>\n",
       "      <td>-0.482490</td>\n",
       "      <td>-1.804602</td>\n",
       "      <td>-0.108230</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>-0.181713</td>\n",
       "      <td>0.257830</td>\n",
       "      <td>-0.027893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "climate   0.086973  0.062299  0.760584 -1.429213  0.119716  0.335818   \n",
       "housing   0.211679  0.126368  0.075721 -0.745475 -1.691264 -0.127419   \n",
       "health    0.225723 -0.337515 -0.018523 -0.426789  0.086243 -0.828912   \n",
       "crime     0.142679  0.430396  0.122182  0.160440  2.018811 -0.216808   \n",
       "trans     0.206439 -0.128435 -0.134167  1.631252  0.558291  0.501944   \n",
       "educate   0.151062 -0.410628 -0.229262 -1.733154  0.655496  0.816060   \n",
       "arts      0.260931 -0.094779  0.010487  0.557111  0.034796 -0.497551   \n",
       "recreate  0.194612  0.265012  0.039771  1.532417 -0.891481  0.610808   \n",
       "economy   0.090317  0.490599 -0.482490 -1.804602 -0.108230 -0.001509   \n",
       "\n",
       "                 6         7         8  \n",
       "climate  -0.187262  0.212050 -0.017525  \n",
       "housing  -0.340491 -0.376762  0.024612  \n",
       "health    0.167000  0.093278 -0.345949  \n",
       "crime     0.135485 -0.261156 -0.029703  \n",
       "trans    -0.839566  0.073868 -0.079099  \n",
       "educate   0.324282 -0.131270  0.064123  \n",
       "arts      0.149089  0.161537  0.434804  \n",
       "recreate  0.684323  0.085608 -0.131808  \n",
       "economy  -0.181713  0.257830 -0.027893  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute component weight matrix\n",
    "# see the \"computation of B in PCA\" in the following link\n",
    "# https://stats.stackexchange.com/questions/126885/methods-to-compute-factor-scores-and-what-is-the-score-coefficient-matrix-in\n",
    "component_weight_matrix = factor_loadings/eigenvalues\n",
    "component_weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38795a2e-af76-476e-b157-7b3d83fbc32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.660169</td>\n",
       "      <td>1.338368</td>\n",
       "      <td>-0.898126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516697</td>\n",
       "      <td>-0.225532</td>\n",
       "      <td>1.051808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.292685</td>\n",
       "      <td>0.308392</td>\n",
       "      <td>0.024139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.759513</td>\n",
       "      <td>-1.464882</td>\n",
       "      <td>-1.193371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.342175</td>\n",
       "      <td>0.173920</td>\n",
       "      <td>0.394625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.081002</td>\n",
       "      <td>-1.691177</td>\n",
       "      <td>-0.042397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-0.648080</td>\n",
       "      <td>1.002819</td>\n",
       "      <td>0.565105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-1.007456</td>\n",
       "      <td>-1.208724</td>\n",
       "      <td>0.179566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-0.196986</td>\n",
       "      <td>-1.209961</td>\n",
       "      <td>0.993437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-1.600565</td>\n",
       "      <td>1.137750</td>\n",
       "      <td>1.279441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0   -0.660169  1.338368 -0.898126\n",
       "1    0.516697 -0.225532  1.051808\n",
       "2   -1.292685  0.308392  0.024139\n",
       "3    0.759513 -1.464882 -1.193371\n",
       "4    1.342175  0.173920  0.394625\n",
       "..        ...       ...       ...\n",
       "324  0.081002 -1.691177 -0.042397\n",
       "325 -0.648080  1.002819  0.565105\n",
       "326 -1.007456 -1.208724  0.179566\n",
       "327 -0.196986 -1.209961  0.993437\n",
       "328 -1.600565  1.137750  1.279441\n",
       "\n",
       "[329 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute scores\n",
    "scores = pd.DataFrame(places.dot(component_weight_matrix[[0,1,2]].values))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00df94-2df7-4b0e-bd96-8064fb7ba48e",
   "metadata": {},
   "source": [
    "## 10: Varimax rotation\n",
    "\n",
    "Sometimes, after conducting Principal Component Analysis, researchers employ \"rotations\" to make their components more interpretable.\n",
    "There are a number of different methodologies for rotating components, but they fall into two main classes: orthogonal rotations and oblique rotations. \n",
    "\n",
    "With an orthogonal rotation, the idea is to plot the factor loadings on the axes of our chosen components and then rotate those axes while preserving orthogonality (all components are perpendicular to each other) until the points are as close to the axes as possible.\n",
    "The goal is to have each factor loads highly on a smaller number of variables.\n",
    "The varimax rotation, used when calculating SoVI, is an example of an orthogonal rotation.\n",
    "This [YouTube video](https://youtu.be/AjrU9oV3MRM) helps visualize what varimax rotation looks like.\n",
    "\n",
    "With an oblique rotation, factors are allowed to become correlated with each other and they are no longer all orthogonal to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dc38161-6b0f-4468-8ff0-ac72e2890dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping # was trying to do this manually, no longer needed\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping # was trying to do this manually, no longer needed\n",
    "# Calculate magnitude of row vectors\n",
    "sums = np.sqrt((top3**2).sum(axis = 1))\n",
    "\n",
    "# Normalize row vectors\n",
    "scaled_loadings = top3.divide(sums, axis = 0)\n",
    "\n",
    "# Check row magnitudes are 1\n",
    "(scaled_loadings**2).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "046ff389-1ffe-4ca3-aa23-dd28acdc58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to do Varimax rotation\n",
    "# The following code is adapted from https://factor-analyzer.readthedocs.io/en/latest/_modules/factor_analyzer/rotator.html\n",
    "# I simply copied it over because I was struggling to understand how varimax rotation works -- I'm struggling to find resources online that explain it in enough detail without being prohibitively mathematically dense\n",
    "def varimax(loadings, normalize = True): \n",
    "    X = loadings.copy()\n",
    "    n_rows, n_cols = X.shape\n",
    "    if n_cols < 2:\n",
    "        return X\n",
    "\n",
    "    # normalize the loadings matrix\n",
    "    # using sqrt of the sum of squares (Kaiser)\n",
    "    if normalize == True:\n",
    "        normalized_mtx = np.apply_along_axis(\n",
    "            lambda x: np.sqrt(np.sum(x**2)), 1, X.copy()\n",
    "        )\n",
    "        X = (X.T / normalized_mtx).T\n",
    "\n",
    "    # initialize the rotation matrix\n",
    "    # to N x N identity matrix\n",
    "    rotation_mtx = np.eye(n_cols)\n",
    "\n",
    "    d = 0\n",
    "    for _ in range(500):\n",
    "\n",
    "        old_d = d\n",
    "\n",
    "        # take inner product of loading matrix\n",
    "        # and rotation matrix\n",
    "        basis = np.dot(X, rotation_mtx)\n",
    "\n",
    "        # transform data for singular value decomposition using updated formula :\n",
    "        # B <- t(x) %*% (z^3 - z %*% diag(drop(rep(1, p) %*% z^2))/p)\n",
    "        diagonal = np.diag(np.squeeze(np.repeat(1, n_rows).dot(basis**2)))\n",
    "        transformed = X.T.dot(basis**3 - basis.dot(diagonal) / n_rows)\n",
    "\n",
    "        # perform SVD on\n",
    "        # the transformed matrix\n",
    "        U, S, V = np.linalg.svd(transformed)\n",
    "\n",
    "        # take inner product of U and V, and sum of S\n",
    "        rotation_mtx = np.dot(U, V)\n",
    "        d = np.sum(S)\n",
    "\n",
    "        # check convergence\n",
    "        if d < old_d * (1 + 1e-5):\n",
    "            break\n",
    "\n",
    "    # take inner product of loading matrix\n",
    "    # and rotation matrix\n",
    "    X = np.dot(X, rotation_mtx)\n",
    "\n",
    "    # de-normalize the data\n",
    "    if normalize == True:\n",
    "        X = X.T * normalized_mtx\n",
    "    else:\n",
    "        X = X.T\n",
    "\n",
    "    # convert loadings matrix to data frame\n",
    "    loadings = X.T.copy()\n",
    "    return loadings, rotation_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "237dbbed-75fb-47f8-a9f3-680b61e58aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.236416</td>\n",
       "      <td>0.859451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.438154</td>\n",
       "      <td>0.545767</td>\n",
       "      <td>0.167306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.829227</td>\n",
       "      <td>0.126177</td>\n",
       "      <td>0.136981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.031006</td>\n",
       "      <td>0.701044</td>\n",
       "      <td>0.141509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.652352</td>\n",
       "      <td>0.288896</td>\n",
       "      <td>-0.027356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.733441</td>\n",
       "      <td>-0.094397</td>\n",
       "      <td>-0.117867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.738407</td>\n",
       "      <td>0.430850</td>\n",
       "      <td>0.151473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.301406</td>\n",
       "      <td>0.645226</td>\n",
       "      <td>0.100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>-0.022131</td>\n",
       "      <td>0.652516</td>\n",
       "      <td>-0.549032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2\n",
       "climate   0.021419  0.236416  0.859451\n",
       "housing   0.438154  0.545767  0.167306\n",
       "health    0.829227  0.126177  0.136981\n",
       "crime     0.031006  0.701044  0.141509\n",
       "trans     0.652352  0.288896 -0.027356\n",
       "educate   0.733441 -0.094397 -0.117867\n",
       "arts      0.738407  0.430850  0.151473\n",
       "recreate  0.301406  0.645226  0.100488\n",
       "economy  -0.022131  0.652516 -0.549032"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement varimax rotation\n",
    "loadings, rotation_mtx = varimax(top3, normalize = True)\n",
    "\n",
    "# View rotated loadings\n",
    "rotated_loadings = pd.DataFrame(loadings, index = [\"climate\", \"housing\", \"health\", \"crime\", \"trans\", \"educate\", \"arts\", \"recreate\", \"economy\"])\n",
    "rotated_loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1484ccd-f5df-4b13-9498-fcbda7ecf34e",
   "metadata": {},
   "source": [
    "## 11: Explained variance and communalities after rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7616dd08-ae5b-45aa-ae79-c1ef941097a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variation Explained:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor</th>\n",
       "      <th>Original</th>\n",
       "      <th>Rotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.297793</td>\n",
       "      <td>2.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.213562</td>\n",
       "      <td>1.981235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.105530</td>\n",
       "      <td>1.154555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Factor  Original   Rotated\n",
       "0       1  3.297793  2.481095\n",
       "1       2  1.213562  1.981235\n",
       "2       3  1.105530  1.154555"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total: 5.616884741577941\n",
      "Rotated total: 5.616884741577941\n"
     ]
    }
   ],
   "source": [
    "variation_explained = pd.DataFrame({\"Factor\": [1,2,3],\n",
    "                                    \"Original\": (top3**2).sum(axis = 0),\n",
    "                                    \"Rotated\": (rotated_loadings**2).sum(axis = 0)})\n",
    "print(\"Variation Explained:\")\n",
    "display(variation_explained)\n",
    "print(\"Original total:\", variation_explained[\"Original\"].sum())\n",
    "print(\"Rotated total:\", variation_explained[\"Original\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf673a0-2e9c-441e-a6e4-3483a9f647e2",
   "metadata": {},
   "source": [
    "As you can see, the total amount of variation explained by the model did not change due to the rotation.\n",
    "However, the amount of variation explained by the first factor dropped substantially, spreading its explained variance to the other two factors.\n",
    "Thus rotations afford us with a cleaner interpretation of the data while explaining the same amount of variation in the data, although the amount of variation explained by each individual factor may change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9751df9-753a-4621-8afe-2d5e8093345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Communality</th>\n",
       "      <th>Rotated Communality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate</td>\n",
       "      <td>0.795007</td>\n",
       "      <td>0.795007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.517832</td>\n",
       "      <td>0.517832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health</td>\n",
       "      <td>0.722302</td>\n",
       "      <td>0.722302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crime</td>\n",
       "      <td>0.512449</td>\n",
       "      <td>0.512449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.509772</td>\n",
       "      <td>0.509772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>educate</td>\n",
       "      <td>0.560739</td>\n",
       "      <td>0.560739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arts</td>\n",
       "      <td>0.753821</td>\n",
       "      <td>0.753821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recreate</td>\n",
       "      <td>0.517259</td>\n",
       "      <td>0.517259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>economy</td>\n",
       "      <td>0.727704</td>\n",
       "      <td>0.727704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable Communality Rotated Communality\n",
       "0   climate    0.795007            0.795007\n",
       "1   housing    0.517832            0.517832\n",
       "2    health    0.722302            0.722302\n",
       "3     crime    0.512449            0.512449\n",
       "4     trans    0.509772            0.509772\n",
       "5   educate    0.560739            0.560739\n",
       "6      arts    0.753821            0.753821\n",
       "7  recreate    0.517259            0.517259\n",
       "8   economy    0.727704            0.727704"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Communalities of first three components\n",
    "communalities_r = pd.DataFrame(columns = {\"Variable\", \"Rotated Communality\"}, index = [i for i in range(len(rotated_loadings))])\n",
    "for i in range(len(top3)):\n",
    "    communalities_r[\"Variable\"][i] = rotated_loadings.index[i]\n",
    "    communalities_r[\"Rotated Communality\"][i] = (rotated_loadings.iloc[i]**2).sum()\n",
    "communalities.merge(communalities_r, on = \"Variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b33e11-3556-440b-b4c5-d57abea90f56",
   "metadata": {},
   "source": [
    "As you can see, the communalities do not change under rotation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284c6d6-7d7f-4341-8660-8339e74578ce",
   "metadata": {},
   "source": [
    "## 12: Calculating scores after rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d1c02e7-cf3c-4611-a7e0-725db9a7bd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11169719,  0.10434053,  0.75270875],\n",
       "       [ 0.07585151,  0.22910478,  0.09092859],\n",
       "       [ 0.38083699, -0.13130707,  0.05414608],\n",
       "       [-0.16786925,  0.42898807,  0.09119147],\n",
       "       [ 0.26288416,  0.02284962, -0.08650412],\n",
       "       [ 0.40556906, -0.23529409, -0.15539194],\n",
       "       [ 0.25828938,  0.08305889,  0.05971669],\n",
       "       [-0.01333983,  0.3288417 ,  0.03704379],\n",
       "       [-0.13133403,  0.44343312, -0.51745538]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute component weight matrix\n",
    "# see the \"PCA's method\" in the following link; have to do some matrix manipulation to get our exact implementation\n",
    "# https://stats.stackexchange.com/questions/126885/methods-to-compute-factor-scores-and-what-is-the-score-coefficient-matrix-in\n",
    "rotated_weight_matrix = np.dot(rotated_loadings, np.linalg.inv(np.dot(rotated_loadings.T, rotated_loadings)))\n",
    "rotated_weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bfa532b-eae8-4034-8a4c-ed45685adb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.144652</td>\n",
       "      <td>0.660634</td>\n",
       "      <td>-1.134468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.340830</td>\n",
       "      <td>0.137161</td>\n",
       "      <td>1.135413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.197845</td>\n",
       "      <td>-0.539361</td>\n",
       "      <td>-0.202436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.689490</td>\n",
       "      <td>-0.706512</td>\n",
       "      <td>-0.890694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.870696</td>\n",
       "      <td>0.953851</td>\n",
       "      <td>0.565216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1.078728</td>\n",
       "      <td>-1.295060</td>\n",
       "      <td>0.166145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-1.209469</td>\n",
       "      <td>0.405216</td>\n",
       "      <td>0.343485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-0.100377</td>\n",
       "      <td>-1.571604</td>\n",
       "      <td>0.167956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.380850</td>\n",
       "      <td>-1.078529</td>\n",
       "      <td>1.086948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-2.167597</td>\n",
       "      <td>-0.063686</td>\n",
       "      <td>0.889225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0   -1.144652  0.660634 -1.134468\n",
       "1    0.340830  0.137161  1.135413\n",
       "2   -1.197845 -0.539361 -0.202436\n",
       "3    1.689490 -0.706512 -0.890694\n",
       "4    0.870696  0.953851  0.565216\n",
       "..        ...       ...       ...\n",
       "324  1.078728 -1.295060  0.166145\n",
       "325 -1.209469  0.405216  0.343485\n",
       "326 -0.100377 -1.571604  0.167956\n",
       "327  0.380850 -1.078529  1.086948\n",
       "328 -2.167597 -0.063686  0.889225\n",
       "\n",
       "[329 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute scores\n",
    "rotated_scores = pd.DataFrame(places.dot(rotated_weight_matrix))\n",
    "rotated_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd7d87-84d0-4df9-9b2a-c5ae428bc075",
   "metadata": {},
   "source": [
    "## 13: Issues with SoVI's implementation of PCA\n",
    "\n",
    "My main concern with using PCA to calculate a social vulnerability index is that PCA is an unsupervised learning technique that does not have any inherent relationship with vulnerability.\n",
    "Rather than relying on knowledge about vulnerability or value judgements, SoVI uses PCA to determine components that explain the most variability in the data.\n",
    "This is what Hinkel refers to as a \"non-substantial argument\", because nothing about the PCA process actually ties the components to the concept of vulnerability (Hinkel, 2011).\n",
    "\n",
    "Additionally, in Cutter et al.'s original SoVI methodology, the authors interpret the meaning of each component, and reverse their directionality if needed (so higher values of the component are associated with a higher degree of vulnerability) before combining the components into a final index (Cutter et al., 2003).\n",
    "For components that should theoretically both increase and decrease vulnerability, Cutter et al. took the absolute value (what do they mean by that???). Spielman et al. choose not to assign meanings to each individual component, because components are not actually trained to represent constructs like personal wealth and density of the built environment (Spielman et al., 2020).\n",
    "A component may load highly on variables associated with these ideas, but these loadings are generated in an unsupervised manner, creating loadings to explain variance rather than to explain a concept.\n",
    "\n",
    "Spielman et al. claim that they address the issue of directionality by switching the direction of variabiles before input into PCA, so that all variables are directly related with their theoretical contribution to vulnerability.\n",
    "However, Schmidtlein et al. claim that \"variables whose signs were adjusted prior to inclusion in the PCA may still load in a manner that indicates that the component would decrease vulnerability\" (Schmidtlein et al., 2008).\n",
    "I don't know how Python and other software calculate eigenvalues and eigenvectors, but I do know that my eigenvectors had the opposite sign of the Penn State tutorial's.\n",
    "Mathematically, the sign of an eigenvector is arbitrary -- regardless of sign, the vector will obey the same relationship that defines eigenvectors.\n",
    "If different software may produce eigenvectors in opposite directions, that raises concerns for me about automating SoVI... perhaps SoVI requires some manual interpretation?\n",
    "But if SoVI requires manual interpretation, how valid can we really say that SoVI is across time?\n",
    "And if SoVI is not comparable over time, does that make it less useful? \n",
    "\n",
    "One final potentiall issue with SoVI is that it treats all factors equally, summing all of the principal components (with eigenvalue greater than 1) with equal weight even though some components explain more variation in the data than others.\n",
    "Would results be more stable if factors were weighted by the percent variance explained?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f9489-e480-46d8-b238-bf059b16a8ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 14: References\n",
    "- Cutter, S. L., Boruff, B. J., & Shirley, W. L. (2003). Social Vulnerability to Environmental Hazards *: Social Vulnerability to Environmental Hazards. Social Science Quarterly, 84(2), 242261. https://doi.org/10.1111/1540-6237.8402002\n",
    "- Hinkel, J. (2011). Indicators of vulnerability and adaptive capacity: Towards a clarification of the sciencepolicy interface. Global Environmental Change, 21(1), 198208. https://doi.org/10.1016/j.gloenvcha.2010.08.002\n",
    "- Schmidtlein, M. C., Deutsch, R. C., Piegorsch, W. W., & Cutter, S. L. (2008). A Sensitivity Analysis of the Social Vulnerability Index. Risk Analysis, 28(4), 10991114. https://doi.org/10.1111/j.1539-6924.2008.01072.x\n",
    "- Spielman, S. E., Tuccillo, J., Folch, D. C., Schweikert, A., Davies, R., Wood, N., & Tate, E. (2020). Evaluating Social Vulnerability Indicators: Criteria and their Application to the Social Vulnerability Index. Natural Hazards, 100(1), 417436. https://doi.org/10.1007/s11069-019-03820-z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228cefbe-6f7c-45e3-bfe2-ecce4d4f7b26",
   "metadata": {},
   "source": [
    "## 15: Further reading\n",
    "- https://stats.oarc.ucla.edu/spss/seminars/efa-spss/\n",
    "- https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c\n",
    "- https://builtin.com/data-science/step-step-explanation-principal-component-analysis\n",
    "- https://towardsdatascience.com/x%E1%B5%80x-covariance-correlation-and-cosine-matrices-d2230997fb7\n",
    "- https://towardsdatascience.com/principal-component-analysis-ac90b73f68f5\n",
    "- https://vitalflux.com/pca-explained-variance-concept-python-example/\n",
    "- https://stats.stackexchange.com/questions/151653/what-is-the-intuitive-reason-behind-doing-rotations-in-factor-analysis-pca-how\n",
    "- https://stats.stackexchange.com/questions/143905/loadings-vs-eigenvectors-in-pca-when-to-use-one-or-another\n",
    "- https://towardsdatascience.com/how-exactly-does-pca-work-5c342c3077fe ( I haven't been able to read this because I don't have a subscription )\n",
    "- https://stats.stackexchange.com/questions/126885/methods-to-compute-factor-scores-and-what-is-the-score-coefficient-matrix-in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb95a32-056f-4495-92c2-c05d4a2e5eeb",
   "metadata": {},
   "source": [
    "## 16: Validating Spielman et al.'s PCA function\n",
    "Here, we will calculate PCA with varimax rotation using Spielman et al.'s function to verify their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d6318af-9789-4a83-833d-bbef377778b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules required for Spielman et al.'s code\n",
    "# from scipy.stats.mstats import zscore as ZSCORE\n",
    "import mdp as MDP\n",
    "import copy\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cac96f9d-adcf-4745-8b93-1a4b3b91489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "places = pd.read_csv(\"places.csv\")\n",
    "\n",
    "# Drop id column\n",
    "places = places.drop(axis = 1, columns = {\"id\"})\n",
    "\n",
    "# Standardize data using sample standard deviation rather than population standard deviation in order to get numbers to match\n",
    "for col in places.columns:\n",
    "    places[col] = np.log10(places[col]) # the tutorial took a log transform to deal with skew\n",
    "    places[col] = ( places[col] - np.mean(places[col]) ) / np.std(places[col], ddof=1) # ddof = 1 is to compute sample standard deviation instead of population standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4a4655d-323a-4006-8f71-65bc917a44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY CHANGE HERE: I calculated the z-score beforehand in order to use the sample rather than population standard deviation to match the tutorial and previous results.\n",
    "class SPSS_PCA:\n",
    "\t'''\n",
    "\tA class that integrates most (all?) of the assumptions SPSS imbeds in their\n",
    "    implimnetation of principal components analysis (PCA), which can be found in\n",
    "    thier GUI under Analyze > Dimension Reduction > Factor. This class is not\n",
    "\tintended to be a full blown recreation of the SPSS Factor Analysis GUI, but\n",
    "\tit does replicate (possibly) the most common use cases. Note that this class\n",
    "\twill not produce exactly the same results as SPSS, probably due to differences\n",
    "\tin how eigenvectors/eigenvalues and/or singular values are computed. However,\n",
    "\tthis class does seem to get all the signs to match, which is not really necessary\n",
    "\tbut kinda nice. Most of the approach came from the official SPSS documentation.\n",
    "\n",
    "\tReferences\n",
    "\t----------\n",
    "\tftp://public.dhe.ibm.com/software/analytics/spss/documentation/statistics/20.0/en/client/Manuals/IBM_SPSS_Statistics_Algorithms.pdf\n",
    "\thttp://spssx-discussion.1045642.n5.nabble.com/Interpretation-of-PCA-td1074350.html\n",
    "\thttp://mdp-toolkit.sourceforge.net/api/mdp.nodes.WhiteningNode-class.html\n",
    "\thttps://github.com/mdp-toolkit/mdp-toolkit/blob/master/mdp/nodes/pca_nodes.py\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tinputs:  numpy array\n",
    "\t\t\t n x k numpy array; n observations and k variables on each observation\n",
    "\treduce:  boolean (default=False)\n",
    "\t\t\t If True, then use eigenvalues to determine which factors to keep; all\n",
    "\t\t\t results will be based on just these factors. If False use all factors.\n",
    "\tmin_eig: float (default=1.0)\n",
    "\t\t\t If reduce=True, then keep all factors with an eigenvalue greater than\n",
    "\t\t\t min_eig. SPSS default is 1.0. If reduce=False, then min_eig is ignored.\n",
    "\tvarimax: boolean (default=False)\n",
    "\t\t\t If True, then apply a varimax rotation to the results. If False, then\n",
    "\t\t\t return the unrotated results only.\n",
    "\n",
    "\tAttributes\n",
    "\t----------\n",
    "\tz_inputs:\tnumpy array\n",
    "\t\t\t\tz-scores of the input array.\n",
    "\tcomp_mat:\tnumpy array\n",
    "\t\t\t\tComponent matrix (a.k.a, \"loadings\").\n",
    "\tscores:\t\tnumpy array\n",
    "\t\t\t\tNew uncorrelated vectors associated with each observation.\n",
    "\teigenvals_all:\tnumpy array\n",
    "\t\t\t\tEigenvalues associated with each factor.\n",
    "\teigenvals:\tnumpy array\n",
    "\t\t\t\tSubset of eigenvalues_all reflecting only those that meet the\n",
    "\t\t\t\tcriterion defined by parameters reduce and min_eig.\n",
    "\tweights:    numpy array\n",
    "\t\t\t\tValues applied to the input data (after z-scores) to get the PCA\n",
    "\t\t\t\tscores. \"Component score coefficient matrix\" in SPSS or\n",
    "\t\t\t\t\"projection matrix\" in the MDP library.\n",
    "\tcomms: \t\tnumpy array\n",
    "\t\t\t\tCommunalities\n",
    "\tsum_sq_load: numpy array\n",
    "\t\t\t\t Sum of squared loadings.\n",
    "\tcomp_mat_rot: numpy array or None\n",
    "\t\t\t\t  Component matrix after rotation. Ordered from highest to lowest\n",
    "\t\t\t\t  variance explained based on sum_sq_load_rot. None if varimax=False.\n",
    "\tscores_rot:\tnumpy array or None\n",
    "\t\t\t\tUncorrelated vectors associated with each observation, after\n",
    "\t\t\t\trotation. None if varimax=False.\n",
    "\tweights_rot: numpy array or None\n",
    "\t\t\t\tRotated values applied to the input data (after z-scores) to get\n",
    "\t\t\t\tthe PCA\tscores. None if varimax=False.\n",
    "\tsum_sq_load_rot: numpy array or None\n",
    "\t\t\t\t Sum of squared loadings for rotated results. None if\n",
    "\t\t\t\t varimax=False.\n",
    "\n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self, inputs, reduce=False, min_eig=1.0, varimax=False):\n",
    "        # Step S1\n",
    "\t\tz_inputs = inputs  # seems necessary for SPSS \"correlation matrix\" setting (their default)\n",
    "        \n",
    "        # The rest is step S2\n",
    "\t\t# run base SPSS-style PCA to get all eigenvalues\n",
    "\t\tpca_node = MDP.nodes.WhiteningNode()  # settings for the PCA\n",
    "\t\tscores = pca_node.execute(z_inputs)  # base run PCA\n",
    "\t\teigenvalues_all = pca_node.d   # rename PCA results\n",
    "\n",
    "\t\t# run SPSS-style PCA based on user settings\n",
    "\t\tpca_node = MDP.nodes.WhiteningNode(reduce=reduce, var_abs=min_eig)  # settings for the PCA\n",
    "\t\tscores = pca_node.execute(z_inputs)  # run PCA  (these have mean=0, std_dev=1)\n",
    "\t\tweights = pca_node.v  # rename PCA results (these might be a transformation of the eigenvectors)\n",
    "\t\teigenvalues = pca_node.d   # rename PCA results\n",
    "\t\tcomponent_matrix = weights * eigenvalues  # compute the loadings\n",
    "\t\tcomponent_matrix = self._reflect(component_matrix)   # get signs to match SPSS\n",
    "\t\tcommunalities = (component_matrix**2).sum(1)   # compute the communalities\n",
    "\t\tsum_sq_loadings = (component_matrix**2).sum(0) # note that this is the same as eigenvalues\n",
    "\t\tweights_reflected = component_matrix/eigenvalues  # get signs to match SPSS\n",
    "\t\tscores_reflected = np.dot(z_inputs, weights_reflected)  # note that abs(scores)=abs(scores_reflected)\n",
    "\n",
    "\t\tif varimax:\n",
    "\t\t\t# SPSS-style varimax rotation prep\n",
    "\t\t\tc_normalizer = 1. / MDP.numx.sqrt(communalities)  # used to normalize inputs to varimax\n",
    "\t\t\tc_normalizer.shape = (component_matrix.shape[0],1)  # reshape to vectorize normalization\n",
    "\t\t\tcm_normalized = c_normalizer * component_matrix  # normalize component matrix for varimax\n",
    "\n",
    "\t\t\t# varimax rotation\n",
    "\t\t\tcm_normalized_varimax = self._varimax(cm_normalized)  # run varimax\n",
    "\t\t\tc_normalizer2 = MDP.numx.sqrt(communalities)  # used to denormalize varimax output\n",
    "\t\t\tc_normalizer2.shape = (component_matrix.shape[0],1)  # reshape to vectorize denormalization\n",
    "\t\t\tcm_varimax = c_normalizer2 * cm_normalized_varimax  # denormalize varimax output\n",
    "\n",
    "\t\t\t# reorder varimax component matrix\n",
    "\t\t\tsorter = (cm_varimax**2).sum(0)  # base the ordering on sum of squared loadings\n",
    "\t\t\tsorter = zip(sorter.tolist(), range(sorter.shape[0]))  # add index to denote current order\n",
    "\t\t\tsorter = sorted(sorter, key=itemgetter(0), reverse=True)  # sort from largest to smallest\n",
    "\t\t\tsum_sq_loadings_varimax, reorderer = zip(*sorter)  # unzip the sorted list\n",
    "\t\t\tsum_sq_loadings_varimax = np.array(sum_sq_loadings_varimax)  # convert to array\n",
    "\t\t\tcm_varimax = cm_varimax[:,reorderer]  # reorder component matrix\n",
    "\n",
    "\t\t\t# varimax scores\n",
    "\t\t\tcm_varimax_reflected = self._reflect(cm_varimax)  # get signs to match SPSS\n",
    "\t\t\tvarimax_weights = np.dot(cm_varimax_reflected,\n",
    "\t\t\t\t\t\t\t  np.linalg.inv(np.dot(cm_varimax_reflected.T,\n",
    "\t\t\t\t\t\t\t  cm_varimax_reflected))) # CM(CM'CM)^-1\n",
    "\t\t\tscores_varimax = np.dot(z_inputs, varimax_weights)\n",
    "\t\telse:\n",
    "\t\t\tcomp_mat_rot = None\n",
    "\t\t\tscores_rot = None\n",
    "\t\t\tweights_rot = None\n",
    "\n",
    "\t\t# assign output variables\n",
    "\t\tself.z_inputs = z_inputs\n",
    "\t\tself.scores = scores_reflected\n",
    "\t\tself.comp_mat = component_matrix\n",
    "\t\tself.eigenvals_all = eigenvalues_all\n",
    "\t\tself.eigenvals = eigenvalues\n",
    "\t\tself.weights = weights_reflected\n",
    "\t\tself.comms = communalities\n",
    "\t\tself.sum_sq_load = sum_sq_loadings\n",
    "\t\tself.comp_mat_rot = cm_varimax_reflected\n",
    "\t\tself.scores_rot = scores_varimax # PCA scores output\n",
    "\t\tself.weights_rot = varimax_weights # PCA weights output\n",
    "\t\tself.sum_sq_load_rot = sum_sq_loadings_varimax\n",
    "\n",
    "\tdef _reflect(self, cm):\n",
    "\t\t# reflect factors with negative sums; SPSS default\n",
    "\t\tcm = copy.deepcopy(cm)\n",
    "\t\treflector = cm.sum(0)\n",
    "\t\tfor column, measure in enumerate(reflector):\n",
    "\t\t\tif measure < 0:\n",
    "\t\t\t\tcm[:,column] = -cm[:,column]\n",
    "\t\treturn cm\n",
    "\n",
    "\tdef _varimax(self, Phi, gamma = 1.0, q = 100, tol = 1e-6):\n",
    "\t\t# downloaded from http://en.wikipedia.org/wiki/Talk%3aVarimax_rotation\n",
    "\t\t# also here http://stackoverflow.com/questions/17628589/perform-varimax-rotation-in-python-using-numpy\n",
    "\t\tp,k = Phi.shape\n",
    "\t\tR = np.eye(k)\n",
    "\t\td=0\n",
    "\t\tfor i in range(q):\n",
    "\t\t\td_old = d\n",
    "\t\t\tLambda = np.dot(Phi, R)\n",
    "\t\t\tu,s,vh = np.linalg.svd(np.dot(Phi.T,np.asarray(Lambda)**3 - (gamma/p) *\n",
    "\t\t\t\t\t\t\tnp.dot(Lambda, np.diag(np.diag(np.dot(Lambda.T,Lambda))))))\n",
    "\t\t\tR = np.dot(u,vh)\n",
    "\t\t\td = np.sum(s)\n",
    "\t\t\tif d_old!=0 and d/d_old < 1 + tol:\n",
    "\t\t\t\tbreak\n",
    "\t\treturn np.dot(Phi, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2e833fd-98ea-4e86-9091-02504aed903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Spielman et al.'s code\n",
    "pca = SPSS_PCA(places.values, reduce=True, varimax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "693a4ab9-9213-42ce-bb95-6b2f4c177159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1     2\n",
       "climate   True  True  True\n",
       "housing   True  True  True\n",
       "health    True  True  True\n",
       "crime     True  True  True\n",
       "trans     True  True  True\n",
       "educate   True  True  True\n",
       "arts      True  True  True\n",
       "recreate  True  True  True\n",
       "economy   True  True  True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test equality of (unrotated) component weight matrices\n",
    "component_weight_matrix[[0,1,2]].round(5).eq( pd.DataFrame(pca.weights.round(5), index = [\"climate\", \"housing\", \"health\", \"crime\", \"trans\", \"educate\", \"arts\", \"recreate\", \"economy\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "774f8383-b53d-41f9-a84e-81b045177b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    329\n",
       "1    329\n",
       "2    329\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test equality of (unrotated) scores\n",
    "pd.DataFrame(pca.scores.round(5)).eq(scores.round(5)).sum() # Note: there are 329 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70b92291-5f44-42f0-83f6-f289f7c0b73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000245</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>-0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000181</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000128</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>-0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>-0.000975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -0.000245  0.001555 -0.000254\n",
       "1 -0.000108  0.000220 -0.000465\n",
       "2  0.000033  0.000254  0.000383\n",
       "3 -0.000181  0.000131 -0.000956\n",
       "4  0.000015 -0.000088  0.000024\n",
       "5  0.000128 -0.000181  0.000611\n",
       "6 -0.000047  0.000221 -0.000105\n",
       "7 -0.000130  0.000073 -0.000701\n",
       "8 -0.000019 -0.001146 -0.000975"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test equality of rotated component weight matrices\n",
    "pd.DataFrame(pca.weights_rot)-rotated_weight_matrix\n",
    "# the rounding method didn't work too well, but this illustrates that the rotated weights are quite similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddb278e0-cdc8-4b53-8ea5-6a8ca13c3128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010060633861689983"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test equality of rotated scores\n",
    "diff = np.abs(pd.DataFrame(pca.scores_rot)-(rotated_scores))\n",
    "max(diff.max()) # here we find a relatively minor maximum difference between the scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

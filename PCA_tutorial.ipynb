{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbef84f-ef31-4e80-9bc1-25aec29dd394",
   "metadata": {},
   "source": [
    "# Steps in Principal Component Analysis\n",
    "Source: https://online.stat.psu.edu/stat505/lesson/11 lessons 11 and 12.\n",
    "\n",
    "You can check our results against theirs starting at 11.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484ed60-ecd3-465c-af4e-2386db3f1fd9",
   "metadata": {},
   "source": [
    "## 0: What does Principal Component Analysis (PCA) do?\n",
    "The goal of PCA is to reduce the dimensionality of input data.\n",
    "Given a large number of input variables, PCA allows us to explain most of the variability of the data with far fewer variables.\n",
    "Principal components are chosen in a way that explains as much of the variation within the data as possible.\n",
    "The first component explains the most variation, followed by the second, etc.\n",
    "Visually, principal components are lines through the data that are as close to the cloud of data as possible, while remaining perpendicular to each other.\n",
    "\n",
    "This YouTube video does a good job of explaining generally what PCA does without explaining any of the math: https://youtu.be/pmG4K79DUoI.\n",
    "The same guy has a follow up video to explain the math, if anyone is interested: https://youtu.be/dhK8nbtii6I.\n",
    "\n",
    "In the rest of this script, we will see step-by-step the operations needed to conduct PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66a331db-80bd-4270-be85-783d859becc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import data\n",
    "places = pd.read_csv(\"places.csv\")\n",
    "\n",
    "# Drop id column\n",
    "places = places.drop(axis = 1, columns = {\"id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb9e93-8e80-4560-a8ed-2915e010a598",
   "metadata": {},
   "source": [
    "## 1: Standardization\n",
    "Calculate the [Z-score](https://www.investopedia.com/terms/z/zscore.asp) for every variable.\n",
    "This prevents any one variable from having more influence than any other variable just because its values and variance tend to be larger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49141257-345a-43e6-9454-a0f4ccd4afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "for col in places.columns:\n",
    "    places[col] = np.log10(places[col]) # the tutorial took a log transform to deal with skew\n",
    "    places[col] = ( places[col] - np.mean(places[col]) ) / np.std(places[col], ddof=1) # ddof = 1 is to compute sample standard deviation instead of population standard deviation\n",
    "    # In some instances, it is preferred to center rather than scale your data. To center, comment out the line above and uncomment the line below \n",
    "    # places[col] = ( places[col] - np.mean(places[col]) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786f559-101b-4294-b7b7-01c259b8fcf4",
   "metadata": {},
   "source": [
    "## 2: Covariance matrix\n",
    "Calculate the [covariance](https://corporatefinanceinstitute.com/resources/data-science/covariance/) between each variable in the standardized dataset and construct a covariance matrix. \n",
    "If we call the standardized matrix $X$, then we calculate the covariance matrix as $X^T X \\frac{1}{n-1}$.\n",
    "Covariance measures the level of variability between two variables.\n",
    "Note that the covariance matrix of the standardized data is equivalent to the Pearson correlation matrix of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8673528-35ce-4e59-a2ce-a266d1d3f81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climate</th>\n",
       "      <th>housing</th>\n",
       "      <th>health</th>\n",
       "      <th>crime</th>\n",
       "      <th>trans</th>\n",
       "      <th>educate</th>\n",
       "      <th>arts</th>\n",
       "      <th>recreate</th>\n",
       "      <th>econ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272964</td>\n",
       "      <td>0.150561</td>\n",
       "      <td>0.227751</td>\n",
       "      <td>0.021559</td>\n",
       "      <td>0.077458</td>\n",
       "      <td>0.172683</td>\n",
       "      <td>0.120610</td>\n",
       "      <td>-0.100727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.272964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431935</td>\n",
       "      <td>0.139234</td>\n",
       "      <td>0.317732</td>\n",
       "      <td>0.202088</td>\n",
       "      <td>0.508501</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.297058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.150561</td>\n",
       "      <td>0.431935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183625</td>\n",
       "      <td>0.418850</td>\n",
       "      <td>0.464764</td>\n",
       "      <td>0.678129</td>\n",
       "      <td>0.254036</td>\n",
       "      <td>0.054047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.227751</td>\n",
       "      <td>0.139234</td>\n",
       "      <td>0.183625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273852</td>\n",
       "      <td>0.055508</td>\n",
       "      <td>0.346462</td>\n",
       "      <td>0.292124</td>\n",
       "      <td>0.276182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.021559</td>\n",
       "      <td>0.317732</td>\n",
       "      <td>0.418850</td>\n",
       "      <td>0.273852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.311237</td>\n",
       "      <td>0.547634</td>\n",
       "      <td>0.390684</td>\n",
       "      <td>0.062680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.077458</td>\n",
       "      <td>0.202088</td>\n",
       "      <td>0.464764</td>\n",
       "      <td>0.055508</td>\n",
       "      <td>0.311237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347899</td>\n",
       "      <td>0.093001</td>\n",
       "      <td>0.128858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.172683</td>\n",
       "      <td>0.508501</td>\n",
       "      <td>0.678129</td>\n",
       "      <td>0.346462</td>\n",
       "      <td>0.547634</td>\n",
       "      <td>0.347899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496519</td>\n",
       "      <td>0.134761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.120610</td>\n",
       "      <td>0.460696</td>\n",
       "      <td>0.254036</td>\n",
       "      <td>0.292124</td>\n",
       "      <td>0.390684</td>\n",
       "      <td>0.093001</td>\n",
       "      <td>0.496519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>econ</th>\n",
       "      <td>-0.100727</td>\n",
       "      <td>0.297058</td>\n",
       "      <td>0.054047</td>\n",
       "      <td>0.276182</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>0.128858</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.175914</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           climate   housing    health     crime     trans   educate  \\\n",
       "climate   1.000000  0.272964  0.150561  0.227751  0.021559  0.077458   \n",
       "housing   0.272964  1.000000  0.431935  0.139234  0.317732  0.202088   \n",
       "health    0.150561  0.431935  1.000000  0.183625  0.418850  0.464764   \n",
       "crime     0.227751  0.139234  0.183625  1.000000  0.273852  0.055508   \n",
       "trans     0.021559  0.317732  0.418850  0.273852  1.000000  0.311237   \n",
       "educate   0.077458  0.202088  0.464764  0.055508  0.311237  1.000000   \n",
       "arts      0.172683  0.508501  0.678129  0.346462  0.547634  0.347899   \n",
       "recreate  0.120610  0.460696  0.254036  0.292124  0.390684  0.093001   \n",
       "econ     -0.100727  0.297058  0.054047  0.276182  0.062680  0.128858   \n",
       "\n",
       "              arts  recreate      econ  \n",
       "climate   0.172683  0.120610 -0.100727  \n",
       "housing   0.508501  0.460696  0.297058  \n",
       "health    0.678129  0.254036  0.054047  \n",
       "crime     0.346462  0.292124  0.276182  \n",
       "trans     0.547634  0.390684  0.062680  \n",
       "educate   0.347899  0.093001  0.128858  \n",
       "arts      1.000000  0.496519  0.134761  \n",
       "recreate  0.496519  1.000000  0.175914  \n",
       "econ      0.134761  0.175914  1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate covariance matrix (covariance matrix of standardized variables is the same as a correlation matrix of the original variables)\n",
    "cov_matrix = (places.T).dot(places)*(1/ (len(places)-1))\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9db548-e33c-4ec7-903e-bb33e734882a",
   "metadata": {},
   "source": [
    "## 3: Eigenvalues and eigenvectors\n",
    "Compute [eigenvalues and eigenvectors](https://math.libretexts.org/Bookshelves/Linear_Algebra/A_First_Course_in_Linear_Algebra_(Kuttler)/07%3A_Spectral_Theory/7.01%3A_Eigenvalues_and_Eigenvectors_of_a_Matrix) of the covariance matrix.\n",
    "An eigenvector $x$ of a matrix $A$ is one such that $Ax = \\lambda x$ for some number $\\lambda$ (left-multiplying the vector by the matrix is the same as multiplying the vector by some constant $\\lambda$).\n",
    "The eigenvectors are our principal components.\n",
    "Each component has an entry for every variable; these entries are called weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80eb083-e428-45ff-8d7a-a8d63b7a5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array\n",
    "cov_matrix = cov_matrix.values\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d4144-1547-474a-8942-ff2140c8db4e",
   "metadata": {},
   "source": [
    "## 4: Rank components\n",
    "Rank the eigenvectors from most to least important by their eigenvalues.\n",
    "The bigger the eigenvalue, the more variance explained by its corresponding component, the more important the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdecb5da-7e20-456d-8be4-536e7b8b1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine eigenvalues and eigenvectors into one list\n",
    "eigenzip = list(zip(eigenvalues, eigenvectors.T))\n",
    "\n",
    "# Sort by eigenvalue \n",
    "sorted_eigenzip = sorted(eigenzip, key = lambda x:x[0], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39f233-2883-49e4-bce3-e0a94732bc45",
   "metadata": {},
   "source": [
    "## 5: Calculate percent variance explained \n",
    "This formula calculates the proportion of variance explained by the ith of all n eigenvectors:\n",
    "\n",
    "$$ \\frac{\\lambda_i}{\\lambda_1 + \\lambda_2 + ... + \\lambda_n} $$\n",
    "\n",
    "And this formula calculates the proportion of variance explained by the first r of all n eigenvectors.\n",
    "\n",
    "$$ \\frac{\\lambda_1 + \\lambda_2 + ... + \\lambda_r}{\\lambda_1 + \\lambda_2 + ... + \\lambda_n} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453e5ed4-a00a-4fd6-9c97-fbf0fa14b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = eigenvalues.sum()\n",
    "\n",
    "eigenval_summary = pd.DataFrame( {\"Component\": np.NaN,\n",
    "                                  \"Eigenvalue\": np.NaN,\n",
    "                                  \"Proportion\": np.NaN,\n",
    "                                  \"Cumulative\": np.NaN},\n",
    "                               index = [i for i in range(len(eigenvalues))])\n",
    "\n",
    "eigenvecs_sorted = pd.DataFrame(eigenvectors)\n",
    "\n",
    "cumulative = 0\n",
    "\n",
    "for i in range(len(sorted_eigenzip)):\n",
    "    eigenval_summary[\"Component\"][i] = i+1\n",
    "    \n",
    "    eigenval_summary[\"Eigenvalue\"][i] = sorted_eigenzip[i][0]\n",
    "    \n",
    "    eigenval_summary[\"Proportion\"][i] = eigenval_summary[\"Eigenvalue\"][i]/tot\n",
    "    \n",
    "    cumulative += eigenval_summary[\"Proportion\"][i]\n",
    "    eigenval_summary[\"Cumulative\"][i] = cumulative\n",
    "    \n",
    "    eigenvecs_sorted[i] = sorted_eigenzip[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05ba54a-ad8f-45a3-b900-3d7027c02738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component</th>\n",
       "      <th>Eigenvalue</th>\n",
       "      <th>Proportion</th>\n",
       "      <th>Cumulative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.297793</td>\n",
       "      <td>0.366421</td>\n",
       "      <td>0.366421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.213562</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>0.501262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.105530</td>\n",
       "      <td>0.122837</td>\n",
       "      <td>0.624098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.907280</td>\n",
       "      <td>0.100809</td>\n",
       "      <td>0.724907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.860629</td>\n",
       "      <td>0.095625</td>\n",
       "      <td>0.820533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.562186</td>\n",
       "      <td>0.062465</td>\n",
       "      <td>0.882998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.483821</td>\n",
       "      <td>0.053758</td>\n",
       "      <td>0.936756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.318072</td>\n",
       "      <td>0.035341</td>\n",
       "      <td>0.972097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.251128</td>\n",
       "      <td>0.027903</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Component  Eigenvalue  Proportion  Cumulative\n",
       "0        1.0    3.297793    0.366421    0.366421\n",
       "1        2.0    1.213562    0.134840    0.501262\n",
       "2        3.0    1.105530    0.122837    0.624098\n",
       "3        4.0    0.907280    0.100809    0.724907\n",
       "4        5.0    0.860629    0.095625    0.820533\n",
       "5        6.0    0.562186    0.062465    0.882998\n",
       "6        7.0    0.483821    0.053758    0.936756\n",
       "7        8.0    0.318072    0.035341    0.972097\n",
       "8        9.0    0.251128    0.027903    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total eigenvalue sum: 9.0\n"
     ]
    }
   ],
   "source": [
    "display(eigenval_summary)\n",
    "print(\"Total eigenvalue sum:\", tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453c45b-f8d6-4a63-9d69-19c9e1dfefc8",
   "metadata": {},
   "source": [
    "## 6: Calculate loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a613cf-5333-4e49-bd89-5a51fe7f346a",
   "metadata": {},
   "source": [
    "The idea here is to normalize all vectors so that they are of unit length.\n",
    "First we will inspect the original eigenvectors, then we will normalize and inspect them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8eabaf-018e-4e06-8d27-3562cf8123ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.157941</td>\n",
       "      <td>0.068629</td>\n",
       "      <td>0.799710</td>\n",
       "      <td>-0.376810</td>\n",
       "      <td>0.041046</td>\n",
       "      <td>0.216695</td>\n",
       "      <td>-0.151352</td>\n",
       "      <td>0.341128</td>\n",
       "      <td>-0.030098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.384405</td>\n",
       "      <td>0.139209</td>\n",
       "      <td>0.079616</td>\n",
       "      <td>-0.196543</td>\n",
       "      <td>-0.579868</td>\n",
       "      <td>-0.082220</td>\n",
       "      <td>-0.275197</td>\n",
       "      <td>-0.606101</td>\n",
       "      <td>0.042269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.409910</td>\n",
       "      <td>-0.371812</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>-0.112522</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>-0.534876</td>\n",
       "      <td>0.134975</td>\n",
       "      <td>0.150058</td>\n",
       "      <td>-0.594128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.259102</td>\n",
       "      <td>0.474132</td>\n",
       "      <td>0.128467</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.692171</td>\n",
       "      <td>-0.139901</td>\n",
       "      <td>0.109504</td>\n",
       "      <td>-0.420125</td>\n",
       "      <td>-0.051012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.374889</td>\n",
       "      <td>-0.141486</td>\n",
       "      <td>-0.141068</td>\n",
       "      <td>0.430077</td>\n",
       "      <td>0.191416</td>\n",
       "      <td>0.323891</td>\n",
       "      <td>-0.678567</td>\n",
       "      <td>0.118833</td>\n",
       "      <td>-0.135843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.274325</td>\n",
       "      <td>-0.452355</td>\n",
       "      <td>-0.241056</td>\n",
       "      <td>-0.456943</td>\n",
       "      <td>0.224744</td>\n",
       "      <td>0.526583</td>\n",
       "      <td>0.262096</td>\n",
       "      <td>-0.211175</td>\n",
       "      <td>0.110124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.473847</td>\n",
       "      <td>-0.104410</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.146881</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>-0.321057</td>\n",
       "      <td>0.120499</td>\n",
       "      <td>0.259867</td>\n",
       "      <td>0.746727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.353412</td>\n",
       "      <td>0.291942</td>\n",
       "      <td>0.041816</td>\n",
       "      <td>0.404019</td>\n",
       "      <td>-0.305654</td>\n",
       "      <td>0.394139</td>\n",
       "      <td>0.553094</td>\n",
       "      <td>0.137718</td>\n",
       "      <td>-0.226365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>0.164013</td>\n",
       "      <td>0.540453</td>\n",
       "      <td>-0.507310</td>\n",
       "      <td>-0.475780</td>\n",
       "      <td>-0.037108</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>-0.146867</td>\n",
       "      <td>0.414774</td>\n",
       "      <td>-0.047903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "climate   0.157941  0.068629  0.799710 -0.376810  0.041046  0.216695   \n",
       "housing   0.384405  0.139209  0.079616 -0.196543 -0.579868 -0.082220   \n",
       "health    0.409910 -0.371812 -0.019475 -0.112522  0.029569 -0.534876   \n",
       "crime     0.259102  0.474132  0.128467  0.042300  0.692171 -0.139901   \n",
       "trans     0.374889 -0.141486 -0.141068  0.430077  0.191416  0.323891   \n",
       "educate   0.274325 -0.452355 -0.241056 -0.456943  0.224744  0.526583   \n",
       "arts      0.473847 -0.104410  0.011026  0.146881  0.011930 -0.321057   \n",
       "recreate  0.353412  0.291942  0.041816  0.404019 -0.305654  0.394139   \n",
       "economy   0.164013  0.540453 -0.507310 -0.475780 -0.037108 -0.000974   \n",
       "\n",
       "                 6         7         8  \n",
       "climate  -0.151352  0.341128 -0.030098  \n",
       "housing  -0.275197 -0.606101  0.042269  \n",
       "health    0.134975  0.150058 -0.594128  \n",
       "crime     0.109504 -0.420125 -0.051012  \n",
       "trans    -0.678567  0.118833 -0.135843  \n",
       "educate   0.262096 -0.211175  0.110124  \n",
       "arts      0.120499  0.259867  0.746727  \n",
       "recreate  0.553094  0.137718 -0.226365  \n",
       "economy  -0.146867  0.414774 -0.047903  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse signs\n",
    "eigenvecs_sorted = (eigenvecs_sorted*-1)#.round(3) # for some reason everything had the opposite sign in ours...\n",
    "# The choice of sign for eigenvectors is arbitrary... but how does that affect our SoVI calculation? \n",
    "# https://github.com/tidymodels/recipes/issues/653\n",
    "# https://www.mathworks.com/help/stats/pca.html\n",
    "\n",
    "# Inspect components\n",
    "eigenvecs_sorted = eigenvecs_sorted.set_index(keys = pd.Index([\"climate\", \"housing\", \"health\", \"crime\", \"trans\", \"educate\", \"arts\", \"recreate\", \"economy\"]))\n",
    "eigenvecs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c054c85-39a0-41d0-a964-bc9b37367770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.286819</td>\n",
       "      <td>0.075603</td>\n",
       "      <td>0.840848</td>\n",
       "      <td>-0.358916</td>\n",
       "      <td>0.038078</td>\n",
       "      <td>0.162476</td>\n",
       "      <td>-0.105276</td>\n",
       "      <td>0.192389</td>\n",
       "      <td>-0.015083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.698073</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>0.083712</td>\n",
       "      <td>-0.187210</td>\n",
       "      <td>-0.537944</td>\n",
       "      <td>-0.061648</td>\n",
       "      <td>-0.191419</td>\n",
       "      <td>-0.341828</td>\n",
       "      <td>0.021182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.744389</td>\n",
       "      <td>-0.409595</td>\n",
       "      <td>-0.020477</td>\n",
       "      <td>-0.107179</td>\n",
       "      <td>0.027432</td>\n",
       "      <td>-0.401045</td>\n",
       "      <td>0.093885</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>-0.297733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.470524</td>\n",
       "      <td>0.522313</td>\n",
       "      <td>0.135076</td>\n",
       "      <td>0.040291</td>\n",
       "      <td>0.642128</td>\n",
       "      <td>-0.104896</td>\n",
       "      <td>0.076168</td>\n",
       "      <td>-0.236942</td>\n",
       "      <td>-0.025563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.680792</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>-0.148325</td>\n",
       "      <td>0.409653</td>\n",
       "      <td>0.177577</td>\n",
       "      <td>0.242851</td>\n",
       "      <td>-0.471992</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>-0.068075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.498170</td>\n",
       "      <td>-0.498323</td>\n",
       "      <td>-0.253456</td>\n",
       "      <td>-0.435244</td>\n",
       "      <td>0.208495</td>\n",
       "      <td>0.394827</td>\n",
       "      <td>0.182307</td>\n",
       "      <td>-0.119098</td>\n",
       "      <td>0.055186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.860498</td>\n",
       "      <td>-0.115020</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.139906</td>\n",
       "      <td>0.011068</td>\n",
       "      <td>-0.240726</td>\n",
       "      <td>0.083815</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>0.374205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.641790</td>\n",
       "      <td>0.321609</td>\n",
       "      <td>0.043967</td>\n",
       "      <td>0.384833</td>\n",
       "      <td>-0.283555</td>\n",
       "      <td>0.295522</td>\n",
       "      <td>0.384717</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>-0.113438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>0.297846</td>\n",
       "      <td>0.595373</td>\n",
       "      <td>-0.533407</td>\n",
       "      <td>-0.453186</td>\n",
       "      <td>-0.034425</td>\n",
       "      <td>-0.000730</td>\n",
       "      <td>-0.102157</td>\n",
       "      <td>0.233924</td>\n",
       "      <td>-0.024005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5  \\\n",
       "climate   0.286819  0.075603  0.840848 -0.358916  0.038078  0.162476   \n",
       "housing   0.698073  0.153355  0.083712 -0.187210 -0.537944 -0.061648   \n",
       "health    0.744389 -0.409595 -0.020477 -0.107179  0.027432 -0.401045   \n",
       "crime     0.470524  0.522313  0.135076  0.040291  0.642128 -0.104896   \n",
       "trans     0.680792 -0.155864 -0.148325  0.409653  0.177577  0.242851   \n",
       "educate   0.498170 -0.498323 -0.253456 -0.435244  0.208495  0.394827   \n",
       "arts      0.860498 -0.115020  0.011593  0.139906  0.011068 -0.240726   \n",
       "recreate  0.641790  0.321609  0.043967  0.384833 -0.283555  0.295522   \n",
       "economy   0.297846  0.595373 -0.533407 -0.453186 -0.034425 -0.000730   \n",
       "\n",
       "                 6         7         8  \n",
       "climate  -0.105276  0.192389 -0.015083  \n",
       "housing  -0.191419 -0.341828  0.021182  \n",
       "health    0.093885  0.084629 -0.297733  \n",
       "crime     0.076168 -0.236942 -0.025563  \n",
       "trans    -0.471992  0.067019 -0.068075  \n",
       "educate   0.182307 -0.119098  0.055186  \n",
       "arts      0.083815  0.146560  0.374205  \n",
       "recreate  0.384717  0.077670 -0.113438  \n",
       "economy  -0.102157  0.233924 -0.024005  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate factor loadings\n",
    "# Here we are just normalizing the eigenvectors, so they are all of unit length\n",
    "# sqrt(eigenvalue) = sqrt(dot product of vector)\n",
    "# Note: will need a different procedure if you chose to center rather than standardize the data\n",
    "factor_loadings = eigenvecs_sorted\n",
    "for i in range( len(eigenvecs_sorted) ):\n",
    "    factor_loadings[i] = factor_loadings[i]*np.sqrt(eigenval_summary[\"Eigenvalue\"][i])\n",
    "factor_loadings#.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520379b-06c6-4a8e-bf12-87deb33ef3a5",
   "metadata": {},
   "source": [
    "Note: we can think of factor loadings as correlations between factors and input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2928f485-eb8d-4a9c-a12c-58245792a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2977929999747135\n",
      "1.213561874929573\n",
      "1.1055298666736546\n",
      "0.9072798419676518\n",
      "0.8606286911898724\n",
      "0.562185798676424\n",
      "0.4838206143490319\n",
      "0.31807215307188164\n",
      "0.25112815916719633\n"
     ]
    }
   ],
   "source": [
    "# Sum of squared loadings: relationship with eigenvalue\n",
    "for i in range(len(factor_loadings)):\n",
    "    print( (factor_loadings[i]**2).sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a13a1f-36ff-4aac-8d81-167b42c1347d",
   "metadata": {},
   "source": [
    "Column-wise, we can see that the sum of the squared loadings for a component equals the component's eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a177ec2-9d98-4357-9e62-1a5a669628d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "0.9999999999999989\n",
      "0.9999999999999992\n",
      "0.9999999999999989\n",
      "0.9999999999999979\n",
      "1.0\n",
      "0.9999999999999991\n",
      "1.0000000000000013\n",
      "1.0000000000000038\n"
     ]
    }
   ],
   "source": [
    "# Communalities\n",
    "for i in range(len(factor_loadings)):\n",
    "    print( (factor_loadings.iloc[i]**2).sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e2fe3-c00b-42f3-9e28-d40d23885604",
   "metadata": {},
   "source": [
    "Row-wise, we can see that the 9 components explain 100% of variance  for each variable, because for each variable, the sum of the squared loadings amongst all of the components is 1.\n",
    "For a given variable, the squared corresponding entry in a component tells you how much variance of that variable is explained by that component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8efd5-fb15-4c00-bf12-2d499f2a9515",
   "metadata": {},
   "source": [
    "## 7: Select components\n",
    "\n",
    "Initially, we derive the same number of components as there are variables in the model.\n",
    "Since the goal is to reduce the dimensionality of the dataset, we typically seek to select a subset of the components.\n",
    "In the Penn State tutorial, the authors select the first three components, and in order to check our results against theirs, we do the same here.\n",
    "SoVI employs the Kaiser criterion, which means retaining all components with eigenvalues of at least 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "216b5a05-8392-42f6-bdc5-c04e7a4213f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3 = factor_loadings[[0,1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab313d-022c-4133-82f9-e59978cc99a0",
   "metadata": {},
   "source": [
    "## 8: Calculate communalities\n",
    "\n",
    "Communalities are calculated as\n",
    "$\\sum_{j=1}^{m} l_{ij}^2$,\n",
    "where $m$ is the number of retained components and $l_{ij}$ is the loading corresponding to variable $i$ and component $j$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976aa862-12de-41df-8b21-adbfb0fdda59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Communality</th>\n",
       "      <th>Variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.795007</td>\n",
       "      <td>climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.517832</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.722302</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512449</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509772</td>\n",
       "      <td>trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.560739</td>\n",
       "      <td>educate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.753821</td>\n",
       "      <td>arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.517259</td>\n",
       "      <td>recreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.727704</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Communality  Variable\n",
       "0    0.795007   climate\n",
       "1    0.517832   housing\n",
       "2    0.722302    health\n",
       "3    0.512449     crime\n",
       "4    0.509772     trans\n",
       "5    0.560739   educate\n",
       "6    0.753821      arts\n",
       "7    0.517259  recreate\n",
       "8    0.727704   economy"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Communalities of first three components\n",
    "communalities = pd.DataFrame(columns = {\"Variable\", \"Communality\"}, index = [i for i in range(len(factor_loadings))])\n",
    "for i in range(len(top3)):\n",
    "    communalities[\"Variable\"][i] = top3.index[i]\n",
    "    communalities[\"Communality\"][i] = (top3.iloc[i]**2).sum()\n",
    "communalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a707252-6633-405f-b921-f19f0ad70b14",
   "metadata": {},
   "source": [
    "Communalities can be interpreted like $R^2$ values in regression models. For example, the first three factors explain 79.5% of the variation in the climate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0311663-fc22-4760-8a48-4045dd535ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.616884741577941"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total communality value\n",
    "communalities[\"Communality\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ee3115-3abb-4f62-b19b-0d1d47d6a52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6240983046197712"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of total variance explained by the 3 factors\n",
    "communalities[\"Communality\"].sum()/len(factor_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8617b2a1-99e9-4721-89bc-57cf07835c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6240983046197713"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, we get the same number by calculating the proportion of variance explained using eigenvalues\n",
    "eigenval_summary[\"Eigenvalue\"][0:3].sum()/eigenval_summary[\"Eigenvalue\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00df94-2df7-4b0e-bd96-8064fb7ba48e",
   "metadata": {},
   "source": [
    "## 9: Varimax rotation\n",
    "\n",
    "Sometimes, after conducting Principal Component Analysis, researchers employ \"rotations\" to make their components more interpretable.\n",
    "There are a number of different methodologies for rotating components, but they fall into two main classes: orthogonal rotations and oblique rotations. \n",
    "\n",
    "With an orthogonal rotation, the idea is to plot the factor loadings on the axes of our chosen components and then rotate those axes while preserving orthogonality (all components are perpendicular to each other) until the points are as close to the axes as possible.\n",
    "The goal is to have each factor loads highly on a smaller number of variables.\n",
    "The varimax rotation, used when calculating SoVI, is an example of an orthogonal rotation.\n",
    "This [YouTube video](https://youtu.be/AjrU9oV3MRM) helps visualize what varimax rotation looks like.\n",
    "\n",
    "With an oblique rotation, factors are allowed to become correlated with each other and they are no longer all orthogonal to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc38161-6b0f-4468-8ff0-ac72e2890dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping # was trying to do this manually, no longer needed\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping # was trying to do this manually, no longer needed\n",
    "# Calculate magnitude of row vectors\n",
    "sums = np.sqrt((top3**2).sum(axis = 1))\n",
    "\n",
    "# Normalize row vectors\n",
    "scaled_loadings = top3.divide(sums, axis = 0)\n",
    "\n",
    "# Check row magnitudes are 1\n",
    "(scaled_loadings**2).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "046ff389-1ffe-4ca3-aa23-dd28acdc58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to do Varimax rotation\n",
    "# The following code is adapted from https://factor-analyzer.readthedocs.io/en/latest/_modules/factor_analyzer/rotator.html\n",
    "# I simply copied it over because I was struggling to understand how varimax rotation works -- I'm struggling to find resources online that explain it in enough detail without being prohibitively mathematically dense\n",
    "def varimax(loadings, normalize = True): \n",
    "    X = loadings.copy()\n",
    "    n_rows, n_cols = X.shape\n",
    "    if n_cols < 2:\n",
    "        return X\n",
    "\n",
    "    # normalize the loadings matrix\n",
    "    # using sqrt of the sum of squares (Kaiser)\n",
    "    if normalize == True:\n",
    "        normalized_mtx = np.apply_along_axis(\n",
    "            lambda x: np.sqrt(np.sum(x**2)), 1, X.copy()\n",
    "        )\n",
    "        X = (X.T / normalized_mtx).T\n",
    "\n",
    "    # initialize the rotation matrix\n",
    "    # to N x N identity matrix\n",
    "    rotation_mtx = np.eye(n_cols)\n",
    "\n",
    "    d = 0\n",
    "    for _ in range(500):\n",
    "\n",
    "        old_d = d\n",
    "\n",
    "        # take inner product of loading matrix\n",
    "        # and rotation matrix\n",
    "        basis = np.dot(X, rotation_mtx)\n",
    "\n",
    "        # transform data for singular value decomposition using updated formula :\n",
    "        # B <- t(x) %*% (z^3 - z %*% diag(drop(rep(1, p) %*% z^2))/p)\n",
    "        diagonal = np.diag(np.squeeze(np.repeat(1, n_rows).dot(basis**2)))\n",
    "        transformed = X.T.dot(basis**3 - basis.dot(diagonal) / n_rows)\n",
    "\n",
    "        # perform SVD on\n",
    "        # the transformed matrix\n",
    "        U, S, V = np.linalg.svd(transformed)\n",
    "\n",
    "        # take inner product of U and V, and sum of S\n",
    "        rotation_mtx = np.dot(U, V)\n",
    "        d = np.sum(S)\n",
    "\n",
    "        # check convergence\n",
    "        if d < old_d * (1 + 1e-5):\n",
    "            break\n",
    "\n",
    "    # take inner product of loading matrix\n",
    "    # and rotation matrix\n",
    "    X = np.dot(X, rotation_mtx)\n",
    "\n",
    "    # de-normalize the data\n",
    "    if normalize == True:\n",
    "        X = X.T * normalized_mtx\n",
    "    else:\n",
    "        X = X.T\n",
    "\n",
    "    # convert loadings matrix to data frame\n",
    "    loadings = X.T.copy()\n",
    "    return loadings, rotation_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "237dbbed-75fb-47f8-a9f3-680b61e58aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.236416</td>\n",
       "      <td>0.859451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <td>0.438154</td>\n",
       "      <td>0.545767</td>\n",
       "      <td>0.167306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0.829227</td>\n",
       "      <td>0.126177</td>\n",
       "      <td>0.136981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.031006</td>\n",
       "      <td>0.701044</td>\n",
       "      <td>0.141509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans</th>\n",
       "      <td>0.652352</td>\n",
       "      <td>0.288896</td>\n",
       "      <td>-0.027356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educate</th>\n",
       "      <td>0.733441</td>\n",
       "      <td>-0.094397</td>\n",
       "      <td>-0.117867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>0.738407</td>\n",
       "      <td>0.430850</td>\n",
       "      <td>0.151473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recreate</th>\n",
       "      <td>0.301406</td>\n",
       "      <td>0.645226</td>\n",
       "      <td>0.100488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>-0.022131</td>\n",
       "      <td>0.652516</td>\n",
       "      <td>-0.549032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2\n",
       "climate   0.021419  0.236416  0.859451\n",
       "housing   0.438154  0.545767  0.167306\n",
       "health    0.829227  0.126177  0.136981\n",
       "crime     0.031006  0.701044  0.141509\n",
       "trans     0.652352  0.288896 -0.027356\n",
       "educate   0.733441 -0.094397 -0.117867\n",
       "arts      0.738407  0.430850  0.151473\n",
       "recreate  0.301406  0.645226  0.100488\n",
       "economy  -0.022131  0.652516 -0.549032"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement varimax rotation\n",
    "loadings, rotation_mtx = varimax(top3, normalize = True)\n",
    "\n",
    "# View rotated loadings\n",
    "rotated_loadings = pd.DataFrame(loadings, index = [\"climate\", \"housing\", \"health\", \"crime\", \"trans\", \"educate\", \"arts\", \"recreate\", \"economy\"])\n",
    "rotated_loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1484ccd-f5df-4b13-9498-fcbda7ecf34e",
   "metadata": {},
   "source": [
    "## 10: Explained variance and communalities after rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7616dd08-ae5b-45aa-ae79-c1ef941097a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variation Explained:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor</th>\n",
       "      <th>Original</th>\n",
       "      <th>Rotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.297793</td>\n",
       "      <td>2.481095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.213562</td>\n",
       "      <td>1.981235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.105530</td>\n",
       "      <td>1.154555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Factor  Original   Rotated\n",
       "0       1  3.297793  2.481095\n",
       "1       2  1.213562  1.981235\n",
       "2       3  1.105530  1.154555"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total: 5.616884741577941\n",
      "Rotated total: 5.616884741577941\n"
     ]
    }
   ],
   "source": [
    "variation_explained = pd.DataFrame({\"Factor\": [1,2,3],\n",
    "                                    \"Original\": (top3**2).sum(axis = 0),\n",
    "                                    \"Rotated\": (rotated_loadings**2).sum(axis = 0)})\n",
    "print(\"Variation Explained:\")\n",
    "display(variation_explained)\n",
    "print(\"Original total:\", variation_explained[\"Original\"].sum())\n",
    "print(\"Rotated total:\", variation_explained[\"Original\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf673a0-2e9c-441e-a6e4-3483a9f647e2",
   "metadata": {},
   "source": [
    "As you can see, the total amount of variation explained by the model did not change due to the rotation.\n",
    "However, the amount of variation explained by the first factor dropped substantially, spreading its explained variance to the other two factors.\n",
    "Thus rotations afford us with a cleaner interpretation of the data while explaining the same amount of variation in the data, although the amount of variation explained by each individual factor may change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9751df9-753a-4621-8afe-2d5e8093345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Communality</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Rotated Communality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.795007</td>\n",
       "      <td>climate</td>\n",
       "      <td>0.795007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.517832</td>\n",
       "      <td>housing</td>\n",
       "      <td>0.517832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.722302</td>\n",
       "      <td>health</td>\n",
       "      <td>0.722302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512449</td>\n",
       "      <td>crime</td>\n",
       "      <td>0.512449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509772</td>\n",
       "      <td>trans</td>\n",
       "      <td>0.509772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.560739</td>\n",
       "      <td>educate</td>\n",
       "      <td>0.560739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.753821</td>\n",
       "      <td>arts</td>\n",
       "      <td>0.753821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.517259</td>\n",
       "      <td>recreate</td>\n",
       "      <td>0.517259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.727704</td>\n",
       "      <td>economy</td>\n",
       "      <td>0.727704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Communality  Variable Rotated Communality\n",
       "0    0.795007   climate            0.795007\n",
       "1    0.517832   housing            0.517832\n",
       "2    0.722302    health            0.722302\n",
       "3    0.512449     crime            0.512449\n",
       "4    0.509772     trans            0.509772\n",
       "5    0.560739   educate            0.560739\n",
       "6    0.753821      arts            0.753821\n",
       "7    0.517259  recreate            0.517259\n",
       "8    0.727704   economy            0.727704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Communalities of first three components\n",
    "communalities_r = pd.DataFrame(columns = {\"Variable\", \"Rotated Communality\"}, index = [i for i in range(len(rotated_loadings))])\n",
    "for i in range(len(top3)):\n",
    "    communalities_r[\"Variable\"][i] = rotated_loadings.index[i]\n",
    "    communalities_r[\"Rotated Communality\"][i] = (rotated_loadings.iloc[i]**2).sum()\n",
    "communalities.merge(communalities_r, on = \"Variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b33e11-3556-440b-b4c5-d57abea90f56",
   "metadata": {},
   "source": [
    "As you can see, the communalities do not change under rotation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd7d87-84d0-4df9-9b2a-c5ae428bc075",
   "metadata": {},
   "source": [
    "## 11: Issues with SoVI's implementation of PCA\n",
    "\n",
    "My main concern with using PCA to calculate a social vulnerability index is that PCA is an unsupervised learning technique that does not have any inherent relationship with vulnerability.\n",
    "Rather than relying on knowledge about vulnerability or value judgements, SoVI uses PCA to determine components that explain the most variability in the data.\n",
    "This is what Hinkel refers to as a \"non-substantial argument\", because nothing about the PCA process actually ties the components to the concept of vulnerability (Hinkel, 2011).\n",
    "\n",
    "Additionally, in Cutter et al.'s original SoVI methodology, the authors interpret the meaning of each component, and reverse their directionality if needed (so higher values of the component are associated with a higher degree of vulnerability) before combining the components into a final index (Cutter et al., 2003).\n",
    "For components that should theoretically both increase and decrease vulnerability, Cutter et al. took the absolute value (what do they mean by that???). Spielman et al. choose not to assign meanings to each individual component, because components are not actually trained to represent constructs like personal wealth and density of the built environment (Spielman et al., 2020).\n",
    "A component may load highly on variables associated with these ideas, but these loadings are generated in an unsupervised manner, creating loadings to explain variance rather than to explain a concept.\n",
    "\n",
    "Spielman et al. claim that they address the issue of directionality by switching the direction of variabiles before input into PCA, so that all variables are directly related with their theoretical contribution to vulnerability.\n",
    "However, Schmidtlein et al. claim that \"variables whose signs were adjusted prior to inclusion in the PCA may still load in a manner that indicates that the component would decrease vulnerability\" (Schmidtlein et al., 2008).\n",
    "I don't know how Python and other software calculate eigenvalues and eigenvectors, but I do know that my eigenvectors had the opposite sign of the Penn State tutorial's.\n",
    "Mathematically, the sign of an eigenvector is arbitrary -- regardless of sign, the vector will obey the same relationship that defines eigenvectors.\n",
    "If different software may produce eigenvectors in opposite directions, that raises concerns for me about automating SoVI... perhaps SoVI requires some manual interpretation?\n",
    "But if SoVI requires manual interpretation, how valid can we really say that SoVI is across time?\n",
    "And if SoVI is not comparable over time, does that make it less useful? \n",
    "\n",
    "One final potentiall issue with SoVI is that it treats all factors equally, summing all of the principal components (with eigenvalue greater than 1) with equal weight even though some components explain more variation in the data than others.\n",
    "Would results be more stable if factors were weighted by the percent variance explained?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f9489-e480-46d8-b238-bf059b16a8ac",
   "metadata": {},
   "source": [
    "## 12: References\n",
    "- Cutter, S. L., Boruff, B. J., & Shirley, W. L. (2003). Social Vulnerability to Environmental Hazards *: Social Vulnerability to Environmental Hazards. Social Science Quarterly, 84(2), 242–261. https://doi.org/10.1111/1540-6237.8402002\n",
    "- Hinkel, J. (2011). “Indicators of vulnerability and adaptive capacity”: Towards a clarification of the science–policy interface. Global Environmental Change, 21(1), 198–208. https://doi.org/10.1016/j.gloenvcha.2010.08.002\n",
    "- Schmidtlein, M. C., Deutsch, R. C., Piegorsch, W. W., & Cutter, S. L. (2008). A Sensitivity Analysis of the Social Vulnerability Index. Risk Analysis, 28(4), 1099–1114. https://doi.org/10.1111/j.1539-6924.2008.01072.x\n",
    "- Spielman, S. E., Tuccillo, J., Folch, D. C., Schweikert, A., Davies, R., Wood, N., & Tate, E. (2020). Evaluating Social Vulnerability Indicators: Criteria and their Application to the Social Vulnerability Index. Natural Hazards, 100(1), 417–436. https://doi.org/10.1007/s11069-019-03820-z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228cefbe-6f7c-45e3-bfe2-ecce4d4f7b26",
   "metadata": {},
   "source": [
    "## 13: Further reading\n",
    "- https://stats.oarc.ucla.edu/spss/seminars/efa-spss/\n",
    "- https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c\n",
    "- https://builtin.com/data-science/step-step-explanation-principal-component-analysis\n",
    "- https://towardsdatascience.com/x%E1%B5%80x-covariance-correlation-and-cosine-matrices-d2230997fb7\n",
    "- https://towardsdatascience.com/principal-component-analysis-ac90b73f68f5\n",
    "- https://vitalflux.com/pca-explained-variance-concept-python-example/\n",
    "- https://stats.stackexchange.com/questions/151653/what-is-the-intuitive-reason-behind-doing-rotations-in-factor-analysis-pca-how\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
